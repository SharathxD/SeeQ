{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "352e37eb06334a17927adcd6164c58e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7182179ff9b4c7f8ddb73ace7754d52",
              "IPY_MODEL_bfd66ddba1d643769589f4a0d32d1c15",
              "IPY_MODEL_9cf9994788b44da3a73e349a0ad70ea3"
            ],
            "layout": "IPY_MODEL_42a7e4651e5145c0b3c9eda2cc5ae203"
          }
        },
        "e7182179ff9b4c7f8ddb73ace7754d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd01dc489262428b9112a84de619c0f7",
            "placeholder": "​",
            "style": "IPY_MODEL_0871e20bdaca4d6cad797df83c838c99",
            "value": "Fetching 6 files: 100%"
          }
        },
        "bfd66ddba1d643769589f4a0d32d1c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c4390631ebb4400a6a723a30a4e8d0b",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2f3a1f7f8524169971b2d72a616f6a0",
            "value": 6
          }
        },
        "9cf9994788b44da3a73e349a0ad70ea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf61c5ee9b9f4e20a7e6f9a1724b50c1",
            "placeholder": "​",
            "style": "IPY_MODEL_8f3c81921e084dea975c5b1468a11088",
            "value": " 6/6 [00:01&lt;00:00,  3.60it/s]"
          }
        },
        "42a7e4651e5145c0b3c9eda2cc5ae203": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd01dc489262428b9112a84de619c0f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0871e20bdaca4d6cad797df83c838c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c4390631ebb4400a6a723a30a4e8d0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2f3a1f7f8524169971b2d72a616f6a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf61c5ee9b9f4e20a7e6f9a1724b50c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f3c81921e084dea975c5b1468a11088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e568a84d53fc4495a88913e8dc3abf41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_507c71f273a942f39828e6ec3d197190",
              "IPY_MODEL_698c40c6048a4286a87ecf7e836a4688",
              "IPY_MODEL_2fb8136896f548d2b167c170cf91a265"
            ],
            "layout": "IPY_MODEL_b9d359a852b64ad781486593abb55c3e"
          }
        },
        "507c71f273a942f39828e6ec3d197190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a425eb1394e84992b846cf150c165018",
            "placeholder": "​",
            "style": "IPY_MODEL_5496466fc3854dbe8bef0ebaaafae8e8",
            "value": "config.json: "
          }
        },
        "698c40c6048a4286a87ecf7e836a4688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c410f51d892b41a595125b1bf844ad7c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36ce03fb052046e7b05d4b03a96fc1c3",
            "value": 1
          }
        },
        "2fb8136896f548d2b167c170cf91a265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed1e63fafdef4d45acd8b28d0638f22e",
            "placeholder": "​",
            "style": "IPY_MODEL_d243bd9264e249748bce01084122f09d",
            "value": " 352k/? [00:00&lt;00:00, 7.42MB/s]"
          }
        },
        "b9d359a852b64ad781486593abb55c3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a425eb1394e84992b846cf150c165018": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5496466fc3854dbe8bef0ebaaafae8e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c410f51d892b41a595125b1bf844ad7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "36ce03fb052046e7b05d4b03a96fc1c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed1e63fafdef4d45acd8b28d0638f22e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d243bd9264e249748bce01084122f09d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e68088ebe76948edbf0848bec4ac9f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eee9fa44d3fb48409ce017e2a5bdd888",
              "IPY_MODEL_57a1d4191fe34a3c94daa0b70c918584",
              "IPY_MODEL_404d3f2964a84a878ac1eb389909c0ea"
            ],
            "layout": "IPY_MODEL_8ff8b33402bb43869bcad3aa4066273d"
          }
        },
        "eee9fa44d3fb48409ce017e2a5bdd888": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d692a4ef1104efeb31ff48153892aa3",
            "placeholder": "​",
            "style": "IPY_MODEL_ca0cf1ea6716465d8bdd6992d7500aeb",
            "value": "inference.json: "
          }
        },
        "57a1d4191fe34a3c94daa0b70c918584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2488bb017141429c92c11bf29ef219d2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff12111d2a1a4cc8ba92f7e863128ba4",
            "value": 1
          }
        },
        "404d3f2964a84a878ac1eb389909c0ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_201bc473e6fc4aaaa8d77a4fb0e5770c",
            "placeholder": "​",
            "style": "IPY_MODEL_edcc2db76c6e41e3b64ff3539eaa780b",
            "value": " 325k/? [00:00&lt;00:00, 8.39MB/s]"
          }
        },
        "8ff8b33402bb43869bcad3aa4066273d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d692a4ef1104efeb31ff48153892aa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca0cf1ea6716465d8bdd6992d7500aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2488bb017141429c92c11bf29ef219d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ff12111d2a1a4cc8ba92f7e863128ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "201bc473e6fc4aaaa8d77a4fb0e5770c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edcc2db76c6e41e3b64ff3539eaa780b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9e492f40fa04806a35f6f5c666aca95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59cdac60b2264bc4ba58cc6974730d23",
              "IPY_MODEL_3a5b884465d9457c8e5d8488b5ebc539",
              "IPY_MODEL_e95140de96474ae99aa202de30673674"
            ],
            "layout": "IPY_MODEL_28e4b90b24254aeeb5f4baae60aabf6e"
          }
        },
        "59cdac60b2264bc4ba58cc6974730d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_127a2d578c614cd99e4b6ee62bcd2866",
            "placeholder": "​",
            "style": "IPY_MODEL_a480e48c73ef46e0b4e1109a0d6fbb87",
            "value": "inference.yml: "
          }
        },
        "3a5b884465d9457c8e5d8488b5ebc539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c33f2d4a654b45d7a7954c1bc39db520",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07536c8343534c069d38b0f1685fe2b1",
            "value": 1
          }
        },
        "e95140de96474ae99aa202de30673674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28e3e32da7df4d0eb1cd64efbfa59ba6",
            "placeholder": "​",
            "style": "IPY_MODEL_feaa8fdbf2e745699745863a42a00037",
            "value": " 148k/? [00:00&lt;00:00, 3.92MB/s]"
          }
        },
        "28e4b90b24254aeeb5f4baae60aabf6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "127a2d578c614cd99e4b6ee62bcd2866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a480e48c73ef46e0b4e1109a0d6fbb87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c33f2d4a654b45d7a7954c1bc39db520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "07536c8343534c069d38b0f1685fe2b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28e3e32da7df4d0eb1cd64efbfa59ba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feaa8fdbf2e745699745863a42a00037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f15d6ee58164ec9a0d004e7f9524780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15141b09976e4e5c96831a3cba417d82",
              "IPY_MODEL_e4a34f9df6674e8386bdbbced719c60e",
              "IPY_MODEL_6f4674a9afa94f14acbaa7a4c68121a7"
            ],
            "layout": "IPY_MODEL_f5cddaf3ee66423389597b85405fbb54"
          }
        },
        "15141b09976e4e5c96831a3cba417d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9794344adc634f93b1c55c92000b85ba",
            "placeholder": "​",
            "style": "IPY_MODEL_f7574b4dda83489d8623130d7a61fb3b",
            "value": "README.md: "
          }
        },
        "e4a34f9df6674e8386bdbbced719c60e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fe9bb936c8a4ddeafd277dd3b6bda1b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebeb458fa7c140dcbc8fee6b11858a68",
            "value": 1
          }
        },
        "6f4674a9afa94f14acbaa7a4c68121a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93c0eae46b83449085d06379ad5dc511",
            "placeholder": "​",
            "style": "IPY_MODEL_bd75caf095874e718f1744e858e9f84a",
            "value": " 15.9k/? [00:00&lt;00:00, 287kB/s]"
          }
        },
        "f5cddaf3ee66423389597b85405fbb54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9794344adc634f93b1c55c92000b85ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7574b4dda83489d8623130d7a61fb3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fe9bb936c8a4ddeafd277dd3b6bda1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ebeb458fa7c140dcbc8fee6b11858a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93c0eae46b83449085d06379ad5dc511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd75caf095874e718f1744e858e9f84a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5a564e60cdc40cfb99ca62432a7af72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b531c37c35834cbfb08700e7e4dc3d14",
              "IPY_MODEL_202bb1443cad46f9878707df72928d3e",
              "IPY_MODEL_0428c01e41f647dc895eb5a118a9580d"
            ],
            "layout": "IPY_MODEL_bf646ef907c9461c803add77b653e5f1"
          }
        },
        "b531c37c35834cbfb08700e7e4dc3d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7ba47850e8540acaef4d9f8f2346ac4",
            "placeholder": "​",
            "style": "IPY_MODEL_3a303c004b284ea4a1a0acf5748c810d",
            "value": ".gitattributes: "
          }
        },
        "202bb1443cad46f9878707df72928d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d5ed43e0692410ba319096e0118c17b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95ec403486f74781ac13999f06fb434e",
            "value": 1
          }
        },
        "0428c01e41f647dc895eb5a118a9580d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e7c9391943246c29130a1265f87a0fb",
            "placeholder": "​",
            "style": "IPY_MODEL_7c77dbce6ef743e1a5be6e77113a8f9e",
            "value": " 1.57k/? [00:00&lt;00:00, 37.1kB/s]"
          }
        },
        "bf646ef907c9461c803add77b653e5f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7ba47850e8540acaef4d9f8f2346ac4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a303c004b284ea4a1a0acf5748c810d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d5ed43e0692410ba319096e0118c17b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "95ec403486f74781ac13999f06fb434e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e7c9391943246c29130a1265f87a0fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c77dbce6ef743e1a5be6e77113a8f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bc3fac4600947a38f6d036931023068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_346e8bde618344de856432a33857cf08",
              "IPY_MODEL_7010610ab61b45c58bd7051eb648a414",
              "IPY_MODEL_ac983f32b7834021b543eb07bd09d36e"
            ],
            "layout": "IPY_MODEL_7c7166d19283460ab40a8f56ea81f3d4"
          }
        },
        "346e8bde618344de856432a33857cf08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de0061381fde48d89e31099deea963be",
            "placeholder": "​",
            "style": "IPY_MODEL_cbd58be746f84ea8a92eadb7d232d515",
            "value": "inference.pdiparams: 100%"
          }
        },
        "7010610ab61b45c58bd7051eb648a414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e7f5aeef0ac4e6dbc526dd02a5732df",
            "max": 84390117,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_738c0caad2304608bc076c4079f62976",
            "value": 84390117
          }
        },
        "ac983f32b7834021b543eb07bd09d36e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8faf3338b91b4b178480d46169a06613",
            "placeholder": "​",
            "style": "IPY_MODEL_143a2569a4684d438ba9b4cb92a0239a",
            "value": " 84.4M/84.4M [00:01&lt;00:00, 92.2MB/s]"
          }
        },
        "7c7166d19283460ab40a8f56ea81f3d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de0061381fde48d89e31099deea963be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbd58be746f84ea8a92eadb7d232d515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e7f5aeef0ac4e6dbc526dd02a5732df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "738c0caad2304608bc076c4079f62976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8faf3338b91b4b178480d46169a06613": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "143a2569a4684d438ba9b4cb92a0239a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xkTw-ylS22WH",
        "outputId": "eac52079-ca8b-4e5e-f71d-da2db031ee3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.4.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.221-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Collecting paddleocr\n",
            "  Downloading paddleocr-3.3.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Collecting paddlex<3.4.0,>=3.3.0 (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
            "  Downloading paddlex-3.3.5-py3-none-any.whl.metadata (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Collecting aistudio-sdk>=0.3.5 (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
            "  Downloading aistudio_sdk-0.3.8-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.12/dist-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (5.2.0)\n",
            "Collecting colorlog (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting modelscope>=1.28.0 (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
            "  Downloading modelscope-1.31.0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.12/dist-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (2.2.2)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.12/dist-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (3.16.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (9.0.0)\n",
            "Requirement already satisfied: pydantic>=2 in /usr/local/lib/python3.12/dist-packages (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (2.11.10)\n",
            "Collecting PyYAML>=5.1 (from pyngrok)\n",
            "  Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting ruamel.yaml (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
            "  Downloading ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting ujson (from paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
            "  Downloading ujson-5.11.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.12/dist-packages (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (1.4.1)\n",
            "Collecting opencv-contrib-python==4.10.0.84 (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
            "  Downloading opencv_contrib_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting pyclipper (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
            "  Downloading pyclipper-1.3.0.post6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting pypdfium2>=4 (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-bidi (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
            "  Downloading python_bidi-0.6.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.12/dist-packages (from paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (2.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Collecting bce-python-sdk (from aistudio-sdk>=0.3.5->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
            "  Downloading bce_python_sdk-0.9.46-py3-none-any.whl.metadata (416 bytes)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (0.4.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (0.2.14)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
            "  Downloading ruamel.yaml.clib-0.2.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pycryptodome>=3.8.0 (from bce-python-sdk->aistudio-sdk>=0.3.5->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr)\n",
            "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: future>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from bce-python-sdk->aistudio-sdk>=0.3.5->paddlex<3.4.0,>=3.3.0->paddlex[ocr-core]<3.4.0,>=3.3.0->paddleocr) (1.0.0)\n",
            "Downloading pyngrok-7.4.1-py3-none-any.whl (25 kB)\n",
            "Downloading ultralytics-8.3.221-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading paddleocr-3.3.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading paddlex-3.3.5-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.5/767.5 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_contrib_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Downloading aistudio_sdk-0.3.8-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading modelscope-1.31.0-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Downloading pyclipper-1.3.0.post6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (963 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.8/963.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.6/300.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.11.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (753 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.1/753.1 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bce_python_sdk-0.9.46-py3-none-any.whl (352 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.6/352.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi, pyclipper, ujson, ruamel.yaml.clib, PyYAML, pypdfium2, pycryptodome, opencv-contrib-python, colorlog, ruamel.yaml, pyngrok, modelscope, bce-python-sdk, aistudio-sdk, ultralytics-thop, paddlex, ultralytics, paddleocr\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0.3\n",
            "    Uninstalling PyYAML-6.0.3:\n",
            "      Successfully uninstalled PyYAML-6.0.3\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.12.0.88\n",
            "    Uninstalling opencv-contrib-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-contrib-python-4.12.0.88\n",
            "Successfully installed PyYAML-6.0.2 aistudio-sdk-0.3.8 bce-python-sdk-0.9.46 colorlog-6.10.1 modelscope-1.31.0 opencv-contrib-python-4.10.0.84 paddleocr-3.3.0 paddlex-3.3.5 pyclipper-1.3.0.post6 pycryptodome-3.23.0 pyngrok-7.4.1 pypdfium2-4.30.0 python-bidi-0.6.7 ruamel.yaml-0.18.16 ruamel.yaml.clib-0.2.14 ujson-5.11.0 ultralytics-8.3.221 ultralytics-thop-2.0.17\n"
          ]
        }
      ],
      "source": [
        "!pip install flask pyngrok pillow ultralytics transformers torch opencv-python matplotlib paddleocr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install num2words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_WPmyV4X3Bfw",
        "outputId": "74e507f8-2be9-4173-e427-ecc772b6c6e8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting num2words\n",
            "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting docopt>=0.6.2 (from num2words)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=5dba9b1a85b2f699811852ac193586edff766d982978b9bb06acca6139a84ab9\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
            "Successfully built docopt\n",
            "Installing collected packages: docopt, num2words\n",
            "Successfully installed docopt-0.6.2 num2words-0.5.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install paddlepaddle-gpu==3.0.0 -i https://www.paddlepaddle.org.cn/packages/stable/cu118/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RBbvIQee3X1p",
        "outputId": "a3b4d5ba-571f-4825-d648-e629caccebdd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://www.paddlepaddle.org.cn/packages/stable/cu118/\n",
            "Collecting paddlepaddle-gpu==3.0.0\n",
            "  Downloading https://paddle-whl.bj.bcebos.com/stable/cu118/paddlepaddle-gpu/paddlepaddle_gpu-3.0.0-cp312-cp312-manylinux1_x86_64.whl (1206.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 GB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from paddlepaddle-gpu==3.0.0) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.12/dist-packages (from paddlepaddle-gpu==3.0.0) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from paddlepaddle-gpu==3.0.0) (5.29.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from paddlepaddle-gpu==3.0.0) (11.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from paddlepaddle-gpu==3.0.0) (4.4.2)\n",
            "Collecting astor (from paddlepaddle-gpu==3.0.0)\n",
            "  Downloading https://paddle-whl.bj.bcebos.com/stable/cu118/astor/astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting opt_einsum==3.3.0 (from paddlepaddle-gpu==3.0.0)\n",
            "  Downloading https://paddle-whl.bj.bcebos.com/stable/cu118/opt-einsum/opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from paddlepaddle-gpu==3.0.0) (3.5)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from paddlepaddle-gpu==3.0.0) (4.15.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.8.89 (from paddlepaddle-gpu==3.0.0)\n",
            "  Downloading https://paddle-whl.bj.bcebos.com/stable/cu118/nvidia-cuda-runtime-cu11/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from paddlepaddle-gpu==3.0.0)\n",
            "  Downloading https://paddle-whl.bj.bcebos.com/stable/cu118/nvidia-cuda-cupti-cu11/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.9.6.50 (from paddlepaddle-gpu==3.0.0)\n",
            "  Downloading https://paddle-whl.bj.bcebos.com/stable/cu118/nvidia-cudnn-cu11/nvidia_cudnn_cu11-8.9.6.50-py3-none-manylinux1_x86_64.whl (699.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m699.9/699.9 MB\u001b[0m \u001b[31m535.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from paddlepaddle-gpu==3.0.0)\n",
            "  Downloading https://paddle-whl.bj.bcebos.com/stable/cu118/nvidia-cublas-cu11/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m903.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from paddlepaddle-gpu==3.0.0)\n",
            "  Downloading https://paddle-whl.bj.bcebos.com/stable/cu118/nvidia-cufft-cu11/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from paddlepaddle-gpu==3.0.0)\n",
            "  Downloading https://paddle-whl.bj.bcebos.com/stable/cu118/nvidia-curand-cu11/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from paddlepaddle-gpu==3.0.0)\n",
            "  Downloading https://paddle-whl.bj.bcebos.com/stable/cu118/nvidia-cusolver-cu11/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from paddlepaddle-gpu==3.0.0)\n",
            "  Downloading https://paddle-whl.bj.bcebos.com/stable/cu118/nvidia-cusparse-cu11/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.19.3 (from paddlepaddle-gpu==3.0.0)\n",
            "  Downloading https://paddle-whl.bj.bcebos.com/stable/cu118/nvidia-nccl-cu11/nvidia_nccl_cu11-2.19.3-py3-none-manylinux1_x86_64.whl (135.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from paddlepaddle-gpu==3.0.0)\n",
            "  Downloading https://paddle-whl.bj.bcebos.com/stable/cu118/nvidia-nvtx-cu11/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.8.89 (from paddlepaddle-gpu==3.0.0)\n",
            "  Downloading https://paddle-whl.bj.bcebos.com/stable/cu118/nvidia-cuda-nvrtc-cu11/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->paddlepaddle-gpu==3.0.0) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx->paddlepaddle-gpu==3.0.0) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->paddlepaddle-gpu==3.0.0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->paddlepaddle-gpu==3.0.0) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->paddlepaddle-gpu==3.0.0) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->paddlepaddle-gpu==3.0.0) (1.3.1)\n",
            "Installing collected packages: opt_einsum, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, astor, nvidia-cusolver-cu11, nvidia-cudnn-cu11, paddlepaddle-gpu\n",
            "  Attempting uninstall: opt_einsum\n",
            "    Found existing installation: opt_einsum 3.4.0\n",
            "    Uninstalling opt_einsum-3.4.0:\n",
            "      Successfully uninstalled opt_einsum-3.4.0\n",
            "Successfully installed astor-0.8.1 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.9.6.50 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.19.3 nvidia-nvtx-cu11-11.8.86 opt_einsum-3.3.0 paddlepaddle-gpu-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-cors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "icuSCf_13aKJ",
        "outputId": "13f17607-f7d3-4d2e-dc4b-90186a139f66"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flask-cors\n",
            "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: flask>=0.9 in /usr/local/lib/python3.12/dist-packages (from flask-cors) (3.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.12/dist-packages (from flask-cors) (3.1.3)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask-cors) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask-cors) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask-cors) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask-cors) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask-cors) (3.0.3)\n",
            "Downloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: flask-cors\n",
            "Successfully installed flask-cors-6.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install IndicTransToolkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "nHFSqW8r5BG-",
        "outputId": "33d59ed9-1057-4dce-d2f1-0f0fcb1aa572"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting IndicTransToolkit\n",
            "  Downloading indictranstoolkit-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.12/dist-packages (from IndicTransToolkit) (3.0.12)\n",
            "Collecting sacremoses (from IndicTransToolkit)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from IndicTransToolkit) (4.57.1)\n",
            "Collecting sacrebleu (from IndicTransToolkit)\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting indic-nlp-library-itt (from IndicTransToolkit)\n",
            "  Downloading indic_nlp_library_itt-0.1.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting morfessor (from indic-nlp-library-itt->IndicTransToolkit)\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library-itt->IndicTransToolkit) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library-itt->IndicTransToolkit) (2.2.2)\n",
            "Collecting sphinx-argparse (from indic-nlp-library-itt->IndicTransToolkit)\n",
            "  Downloading sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting sphinx-rtd-theme (from indic-nlp-library-itt->IndicTransToolkit)\n",
            "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting portalocker (from sacrebleu->IndicTransToolkit)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu->IndicTransToolkit) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu->IndicTransToolkit) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->IndicTransToolkit)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu->IndicTransToolkit) (5.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from sacremoses->IndicTransToolkit) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from sacremoses->IndicTransToolkit) (1.5.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sacremoses->IndicTransToolkit) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers->IndicTransToolkit) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers->IndicTransToolkit) (0.35.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->IndicTransToolkit) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers->IndicTransToolkit) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->IndicTransToolkit) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->IndicTransToolkit) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->IndicTransToolkit) (0.6.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->IndicTransToolkit) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->IndicTransToolkit) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->IndicTransToolkit) (1.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->indic-nlp-library-itt->IndicTransToolkit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->indic-nlp-library-itt->IndicTransToolkit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->indic-nlp-library-itt->IndicTransToolkit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->IndicTransToolkit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->IndicTransToolkit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->IndicTransToolkit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->IndicTransToolkit) (2025.10.5)\n",
            "Requirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from sphinx-argparse->indic-nlp-library-itt->IndicTransToolkit) (8.2.3)\n",
            "Requirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.12/dist-packages (from sphinx-argparse->indic-nlp-library-itt->IndicTransToolkit) (0.21.2)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library-itt->IndicTransToolkit)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library-itt->IndicTransToolkit) (1.17.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->IndicTransToolkit) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->IndicTransToolkit) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->IndicTransToolkit) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->IndicTransToolkit) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->IndicTransToolkit) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->IndicTransToolkit) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->IndicTransToolkit) (3.1.6)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->IndicTransToolkit) (2.19.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->IndicTransToolkit) (3.0.1)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->IndicTransToolkit) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->IndicTransToolkit) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->IndicTransToolkit) (1.4.1)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->IndicTransToolkit) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from Jinja2>=3.1->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library-itt->IndicTransToolkit) (3.0.3)\n",
            "Downloading indictranstoolkit-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (546 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m546.3/546.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading indic_nlp_library_itt-0.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\n",
            "Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: morfessor, sacremoses, portalocker, colorama, sacrebleu, sphinxcontrib-jquery, sphinx-argparse, sphinx-rtd-theme, indic-nlp-library-itt, IndicTransToolkit\n",
            "Successfully installed IndicTransToolkit-1.1.1 colorama-0.4.6 indic-nlp-library-itt-0.1.1 morfessor-2.0.6 portalocker-3.2.0 sacrebleu-2.5.1 sacremoses-0.1.1 sphinx-argparse-0.5.2 sphinx-rtd-theme-3.0.2 sphinxcontrib-jquery-4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sphinxcontrib"
                ]
              },
              "id": "6fc69a4ada014ef5af32210507dd2d2e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --force-reinstall torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "ITeHziIm5NgD",
        "outputId": "1e9a8c4b-bcc6-434a-e7e8-4bd155889894"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting filelock (from torch)\n",
            "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting setuptools (from torch)\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx>=2.5.1 (from torch)\n",
            "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec>=0.8.5 (from torch)\n",
            "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
            "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.5.0 (from torch)\n",
            "  Downloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting numpy (from torchvision)\n",
            "  Downloading numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
            "  Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
            "Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m827.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m890.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, typing-extensions, triton, sympy, setuptools, pillow, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvshmem-cu12\n",
            "    Found existing installation: nvidia-nvshmem-cu12 3.4.5\n",
            "    Uninstalling nvidia-nvshmem-cu12-3.4.5:\n",
            "      Successfully uninstalled nvidia-nvshmem-cu12-3.4.5\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.5\n",
            "    Uninstalling networkx-3.5:\n",
            "      Successfully uninstalled networkx-3.5\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.3\n",
            "    Uninstalling MarkupSafe-3.0.3:\n",
            "      Successfully uninstalled MarkupSafe-3.0.3\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.20.0\n",
            "    Uninstalling filelock-3.20.0:\n",
            "      Successfully uninstalled filelock-3.20.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.8.0+cu126\n",
            "    Uninstalling torchaudio-2.8.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.9.0 which is incompatible.\n",
            "gradio 5.49.1 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\n",
            "fastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.0 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.3 filelock-3.20.0 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 numpy-2.3.4 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 pillow-12.0.0 setuptools-80.9.0 sympy-1.14.0 torch-2.9.0 torchaudio-2.9.0 torchvision-0.24.0 triton-3.5.0 typing-extensions-4.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "numpy"
                ]
              },
              "id": "95bacd54837b40e9a479373c3e4843e4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import json\n",
        "import tempfile\n",
        "import sys\n",
        "import statistics\n",
        "from typing import List, Tuple\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "from werkzeug.utils import secure_filename\n",
        "from pyngrok import ngrok\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import torch\n",
        "\n",
        "# --- Import Colab-specific modules ---\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    # For visualization in Colab\n",
        "    from IPython.display import display, HTML\n",
        "    import matplotlib.pyplot as plt\n",
        "except ImportError:\n",
        "    print(\"Warning: Running outside Colab. Visualization will be disabled.\")\n",
        "    def display_image_in_colab(img, title=\"Processed Image\"): pass\n",
        "    pass\n",
        "\n",
        "\n",
        "# --- ML Model Imports (VLM/YOLO/OCR) ---\n",
        "try:\n",
        "    from transformers import AutoProcessor, AutoModelForImageTextToText\n",
        "    from ultralytics import YOLO\n",
        "    from paddleocr import PaddleOCR\n",
        "    import logging\n",
        "    logging.getLogger('ppocr').setLevel(logging.ERROR)\n",
        "except ImportError:\n",
        "    print(\"Warning: Core ML libraries (VLM/YOLO/OCR) not found. Ensure you run the pip install commands.\")\n",
        "\n",
        "# --- TRANSLATION Model Imports ---\n",
        "try:\n",
        "    from transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig, AutoTokenizer\n",
        "    from IndicTransToolkit.processor import IndicProcessor\n",
        "except ImportError:\n",
        "    print(\"Warning: IndicTrans2 libraries not found. Translation will be disabled.\")\n",
        "    # Define placeholder variables if imports fail\n",
        "    AutoModelForSeq2SeqLM = None\n",
        "    BitsAndBytesConfig = None\n",
        "    AutoTokenizer = None\n",
        "    IndicProcessor = None\n",
        "\n",
        "\n",
        "# ------------------- Helper Function for Colab Visualization -------------------\n",
        "\n",
        "def display_image_in_colab(img, title=\"Processed Image\"):\n",
        "    \"\"\"Displays a PIL image in the Colab output using matplotlib.\"\"\"\n",
        "    if 'google.colab' not in sys.modules:\n",
        "        return # Skip visualization if not in Colab\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(img)\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# ------------------- Global Translation Constants -------------------\n",
        "TRANSLATION_BATCH_SIZE = 4\n",
        "TRANSLATION_QUANTIZATION = None # Set to \"4-bit\" or \"8-bit\" if needed\n",
        "# Hardcoded Target Language: Telugu (tel_Telu)\n",
        "# Other options: tamil='tam_Taml', telugu='tel_Telu', hindi='hin_Deva', malyalam='mal_Mlym'\n",
        "#Kannada =\"kan_Knda\"\n",
        "TARGET_LANG_CODE = \"kan_Knda\"\n",
        "TARGET_LANG_NAME = \"kannada\"\n",
        "SOURCE_LANG_CODE = \"eng_Latn\" # Source Language: English\n",
        "\n",
        "\n",
        "# ------------------- Translation Helper Functions -------------------\n",
        "\n",
        "def initialize_translation_model_and_tokenizer(ckpt_dir, quantization, token):\n",
        "    \"\"\"Initializes the IndicTrans2 model and tokenizer.\"\"\"\n",
        "    if not AutoModelForSeq2SeqLM: return None, None\n",
        "\n",
        "    if quantization == \"4-bit\":\n",
        "        qconfig = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "        )\n",
        "        model_dtype = torch.bfloat16\n",
        "    elif quantization == \"8-bit\":\n",
        "        qconfig = BitsAndBytesConfig(\n",
        "            load_in_8bit=True,\n",
        "            bnb_8bit_use_double_quant=True,\n",
        "            bnb_8bit_compute_dtype=torch.bfloat16,\n",
        "        )\n",
        "        model_dtype = torch.bfloat16\n",
        "    else:\n",
        "        qconfig = None\n",
        "        # CRITICAL FIX: Explicitly set model dtype to float32 for maximum stability on T5/BART architectures.\n",
        "        # This prevents the 'NoneType' shape error caused by unstable half-precision (model.half()).\n",
        "        model_dtype = torch.bfloat16\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(ckpt_dir, trust_remote_code=True, use_auth_token=token)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "        ckpt_dir,\n",
        "        trust_remote_code=True,\n",
        "        low_cpu_mem_usage=True,\n",
        "        quantization_config=qconfig,\n",
        "        torch_dtype=model_dtype, # Use the explicitly set stable dtype\n",
        "        use_auth_token=token\n",
        "    ).to(DEVICE) # Move model to device\n",
        "\n",
        "    # Explicitly removing the model.half() call for stability\n",
        "    model.eval()\n",
        "    return tokenizer, model\n",
        "\n",
        "\n",
        "def batch_translate(input_sentences, src_lang, tgt_lang, model, tokenizer, ip):\n",
        "    \"\"\"Translates a batch of sentences using IndicTrans2.\"\"\"\n",
        "    if not model: return [\"Translation model unavailable.\" for _ in input_sentences]\n",
        "\n",
        "    translations = []\n",
        "    for i in range(0, len(input_sentences), TRANSLATION_BATCH_SIZE):\n",
        "        batch = input_sentences[i : i + TRANSLATION_BATCH_SIZE]\n",
        "\n",
        "        # Preprocess the batch and extract entity mappings\n",
        "        batch = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n",
        "\n",
        "        # Tokenize the batch and generate input encodings\n",
        "        inputs = tokenizer(\n",
        "            batch,\n",
        "            truncation=True,\n",
        "            padding=\"longest\",\n",
        "            return_tensors=\"pt\",\n",
        "            return_attention_mask=True,\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        # Generate translations using the model\n",
        "        with torch.no_grad():\n",
        "            generated_tokens = model.generate(\n",
        "                **inputs,\n",
        "                use_cache=False,\n",
        "                min_length=0,\n",
        "                max_length=256,\n",
        "                num_beams=5,\n",
        "                num_return_sequences=1,\n",
        "            )\n",
        "\n",
        "        # Decode the generated tokens into text\n",
        "        generated_tokens = tokenizer.batch_decode(\n",
        "            generated_tokens,\n",
        "            skip_special_tokens=True,\n",
        "            clean_up_tokenization_spaces=True,\n",
        "        )\n",
        "\n",
        "        # Postprocess the translations, including entity replacement\n",
        "        translations += ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
        "\n",
        "        # --- Memory Cleanup after Translation ---\n",
        "        del inputs\n",
        "        # Use torch.cuda.empty_cache() only if on GPU\n",
        "        if DEVICE == \"cuda\":\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    return translations\n",
        "\n",
        "\n",
        "# ------------------- Initialize Models and Device -------------------\n",
        "print(\"Initializing models...\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "DEVICE = device # Set the global device for translation\n",
        "\n",
        "# --- Load SmolVLM2 ---\n",
        "vlm_model_path = \"HuggingFaceTB/SmolVLM2-256M-Video-Instruct\"\n",
        "try:\n",
        "    processor = AutoProcessor.from_pretrained(vlm_model_path)\n",
        "    # Check for bfloat16 compatibility (Ampere architecture or newer)\n",
        "    use_bfloat16 = device == \"cuda\" and torch.cuda.get_device_capability()[0] >= 8\n",
        "    model_vlm = AutoModelForImageTextToText.from_pretrained(\n",
        "        vlm_model_path,\n",
        "        dtype=torch.bfloat16 if use_bfloat16 else torch.float32,\n",
        "        _attn_implementation=\"eager\"\n",
        "    ).to(device).eval()\n",
        "    print(\"SmolVLM2 loaded.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading SmolVLM2: {e}\")\n",
        "    model_vlm = None\n",
        "\n",
        "# --- Load YOLO ---\n",
        "yolo_model_path = \"yolo11n.pt\"\n",
        "try:\n",
        "    if not os.path.exists(yolo_model_path):\n",
        "        print(\"Downloading YOLO11n model...\")\n",
        "        yolo_model = YOLO(\"yolo11n.pt\")\n",
        "    else:\n",
        "        yolo_model = YOLO(yolo_model_path)\n",
        "    print(\"YOLO model loaded.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading YOLO: {e}\")\n",
        "    yolo_model = None\n",
        "\n",
        "# --- Load PaddleOCR ---\n",
        "print(\"Loading PaddleOCR...\")\n",
        "try:\n",
        "    ocr_model = PaddleOCR(use_angle_cls=True, lang=\"en\")\n",
        "    print(\"PaddleOCR loaded.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading PaddleOCR: {e}\")\n",
        "    ocr_model = None\n",
        "\n",
        "# --- Load IndicTrans2 (EN->Indic) ---\n",
        "en_indic_tokenizer, en_indic_model, indic_processor = None, None, None\n",
        "if AutoModelForSeq2SeqLM:\n",
        "    print(\"Loading IndicTrans2 model...\")\n",
        "    en_indic_ckpt_dir = \"ai4bharat/indictrans2-en-indic-dist-200M\"\n",
        "    try:\n",
        "        # Assuming 'hf' token is available via Colab userdata\n",
        "        hf_token = userdata.get('hf') if 'google.colab' in sys.modules else \"\"\n",
        "        en_indic_tokenizer, en_indic_model = initialize_translation_model_and_tokenizer(\n",
        "            en_indic_ckpt_dir, TRANSLATION_QUANTIZATION, hf_token\n",
        "        )\n",
        "        indic_processor = IndicProcessor(inference=True)\n",
        "        print(f\"IndicTrans2 loaded for translation to {TARGET_LANG_NAME}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading IndicTrans2: {e}\")\n",
        "        en_indic_tokenizer, en_indic_model, indic_processor = None, None, None\n",
        "\n",
        "\n",
        "# ------------------- Other Helper Functions (yolo_detect, get_relative_positions, vlm_caption, OCR helpers) -------------------\n",
        "\n",
        "def yolo_detect(img):\n",
        "    \"\"\"\n",
        "    Run YOLO detection on a PIL Image and return objects with bounding boxes.\n",
        "    \"\"\"\n",
        "    if not yolo_model: return []\n",
        "    try:\n",
        "        results = yolo_model.predict(img, verbose=False, conf=0.5)\n",
        "        result = results[0]\n",
        "        objects_info = []\n",
        "\n",
        "        if len(result.boxes) > 0:\n",
        "            for cls, box in zip(result.boxes.cls, result.boxes.xyxy):\n",
        "                class_name = yolo_model.names[int(cls.item())]\n",
        "                x1, y1, x2, y2 = [int(coord) for coord in box.tolist()]\n",
        "                objects_info.append({\"name\": class_name, \"box\": (x1, y1, x2, y2)})\n",
        "            print(f\"[DEBUG:YOLO] Detected {len(objects_info)} objects.\")\n",
        "        else:\n",
        "            print(\"[DEBUG:YOLO] No objects detected.\")\n",
        "        return objects_info\n",
        "    except Exception as e:\n",
        "        print(f\"[DEBUG:YOLO] Error during prediction: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def get_relative_positions(objects):\n",
        "    \"\"\"Compute relative positions between all pairs of objects\"\"\"\n",
        "    relations = []\n",
        "    for i in range(len(objects)):\n",
        "        name_i, box_i = objects[i][\"name\"], objects[i][\"box\"]\n",
        "        x1_i, y1_i, x2_i, y2_i = box_i\n",
        "        cx_i, cy_i = (x1_i+x2_i)/2, (y1_i+y2_i)/2\n",
        "        for j in range(len(objects)):\n",
        "            if i == j: continue\n",
        "            name_j, box_j = objects[j][\"name\"], objects[j][\"box\"]\n",
        "            x1_j, y1_j, x2_j, y2_j = box_j\n",
        "            cx_j, cy_j = (x1_j+x2_j)/2, (y1_j+y2_j)/2\n",
        "\n",
        "            horiz = \"left of\" if cx_i < cx_j else \"right of\" if cx_i > cx_j else \"horizontally aligned with\"\n",
        "            vert = \"above\" if cy_i < cy_j else \"below\" if cy_i > cy_j else \"vertically aligned with\"\n",
        "\n",
        "            if abs(cx_i - cx_j) < 50 and abs(cy_i - cy_j) < 50:\n",
        "                relations.append(f\"{name_i} is centered near {name_j}\")\n",
        "            elif horiz == \"horizontally aligned with\":\n",
        "                relations.append(f\"{name_i} is {vert} {name_j}\")\n",
        "            elif vert == \"vertically aligned with\":\n",
        "                 relations.append(f\"{name_i} is {horiz} {name_j}\")\n",
        "            else:\n",
        "                relations.append(f\"{name_i} is {horiz} and {vert} {name_j}\")\n",
        "    return relations[:10] # Limit output relations\n",
        "\n",
        "def vlm_caption(image, prompt):\n",
        "    \"\"\"Generate caption from VLM\"\"\"\n",
        "    if not model_vlm: return \"VLM model is unavailable.\"\n",
        "    print(f\"[DEBUG:VLM] Starting caption generation with prompt: '{prompt[:50]}...'\")\n",
        "    try:\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"image\", \"image\": image},\n",
        "                    {\"type\": \"text\", \"text\": prompt}\n",
        "                ],\n",
        "            }\n",
        "        ]\n",
        "        inputs = processor.apply_chat_template(\n",
        "            messages,\n",
        "            add_generation_prompt=True,\n",
        "            tokenize=True,\n",
        "            return_tensors=\"pt\",\n",
        "            return_dict=True,\n",
        "        ).to(model_vlm.device)\n",
        "\n",
        "        generated_ids = model_vlm.generate(**inputs, max_new_tokens=50)\n",
        "\n",
        "        # --- GPU Memory Cleanup ---\n",
        "        del inputs\n",
        "        if model_vlm.device.type == \"cuda\":\n",
        "            torch.cuda.empty_cache()\n",
        "        # --------------------------\n",
        "\n",
        "        response = processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
        "        if \"Assistant:\" in response:\n",
        "            response = response.split(\"Assistant:\")[-1].strip()\n",
        "        print(f\"[DEBUG:VLM] Caption generated successfully.\")\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(f\"[VLM Error]: {e}\")\n",
        "        return \"Error analyzing image.\"\n",
        "\n",
        "# --- OCR helper utilities ---\n",
        "\n",
        "def _normalize_bbox(poly: List[float]) -> Tuple[float,float,float,float]:\n",
        "    \"\"\"\n",
        "    Normalize bbox representation from PaddleOCR varied formats to (xmin, ymin, xmax, ymax).\n",
        "    \"\"\"\n",
        "    if not poly: return (0.0, 0.0, 0.0, 0.0)\n",
        "    if len(poly) >= 8:\n",
        "        xs = poly[0::2]\n",
        "        ys = poly[1::2]\n",
        "        xmin, xmax = min(xs), max(xs)\n",
        "        ymin, ymax = min(ys), max(ys)\n",
        "    elif len(poly) >= 4:\n",
        "        xmin, ymin, xmax, ymax = poly[0], poly[1], poly[2], poly[3]\n",
        "    else:\n",
        "        xmin = ymin = xmax = ymax = 0.0\n",
        "    return float(xmin), float(ymin), float(xmax), float(ymax)\n",
        "\n",
        "\n",
        "def _parse_paddle_result(result) -> List[dict]:\n",
        "    \"\"\"\n",
        "    Return list of dicts: {'text': str, 'bbox': (xmin,ymin,xmax,ymax)}\n",
        "    Handles common PaddleOCR formats:\n",
        "     - parsing_res_list / PP-Structure style\n",
        "     - list-of-dicts with 'rec_res' and 'dt_boxes'\n",
        "     - legacy nested list format [[(box, (text, conf)), ...], ...] or flat list\n",
        "    \"\"\"\n",
        "    items = []\n",
        "\n",
        "    # Case: structured parsing_res_list (PP-Structure style)\n",
        "    if isinstance(result, list) and len(result) > 0 and isinstance(result[0], dict) and 'parsing_res_list' in result[0]:\n",
        "        for page in result:\n",
        "            for elem in page.get('parsing_res_list', []):\n",
        "                text = elem.get('text') or elem.get('rec_text') or \"\"\n",
        "                bbox = elem.get('bbox') or elem.get('box') or None\n",
        "                if bbox is not None:\n",
        "                    items.append({'text': text, 'bbox': _normalize_bbox(bbox)})\n",
        "        return items\n",
        "\n",
        "    # Case: list-of-dicts where rec_res/dt_boxes present\n",
        "    if isinstance(result, list) and len(result) > 0 and isinstance(result[0], dict) and ('rec_res' in result[0] or 'dt_boxes' in result[0] or 'rec_texts' in result[0]):\n",
        "        for page in result:\n",
        "            recs = page.get('rec_res') or page.get('rec_res_list') or page.get('rec_texts') or []\n",
        "            boxes = page.get('dt_boxes') or page.get('dt_res') or page.get('box') or []\n",
        "            # pair boxes and recs when possible\n",
        "            if boxes and len(boxes) == len(recs):\n",
        "                for box, rec in zip(boxes, recs):\n",
        "                    # rec may be [text, conf] or dict\n",
        "                    text = rec[0] if isinstance(rec, (list, tuple)) and len(rec) > 0 else (rec.get('text') if isinstance(rec, dict) else str(rec))\n",
        "                    items.append({'text': text, 'bbox': _normalize_bbox(box)})\n",
        "            else:\n",
        "                # fallback: if recs is list of strings\n",
        "                if isinstance(recs, list) and all(isinstance(r, str) for r in recs):\n",
        "                    for i, text in enumerate(recs):\n",
        "                        box = boxes[i] if i < len(boxes) else None\n",
        "                        items.append({'text': text, 'bbox': _normalize_bbox(box) if box is not None else (0.0,0.0,0.0,0.0)})\n",
        "        return items\n",
        "\n",
        "    # Case: legacy nested list format: result = [[ [box, (text, conf)], ... ], ...]\n",
        "    if isinstance(result, list) and len(result) > 0:\n",
        "        # If top-level is pages\n",
        "        maybe_page = result[0]\n",
        "        if isinstance(maybe_page, list) and len(maybe_page) > 0 and isinstance(maybe_page[0], list):\n",
        "            page = maybe_page\n",
        "            for line_data in page:\n",
        "                if not (isinstance(line_data, list) and len(line_data) >= 2):\n",
        "                    continue\n",
        "                box = line_data[0]\n",
        "                rec = line_data[1]\n",
        "                text = rec[0] if isinstance(rec, (list, tuple)) else (rec.get('text') if isinstance(rec, dict) else str(rec))\n",
        "                items.append({'text': text, 'bbox': _normalize_bbox(box)})\n",
        "            return items\n",
        "\n",
        "        # fallback: flat list of (box,(text,conf)) or dicts\n",
        "        for entry in result:\n",
        "            if isinstance(entry, list) and len(entry) >= 2:\n",
        "                box = entry[0]\n",
        "                rec = entry[1]\n",
        "                text = rec[0] if isinstance(rec, (list, tuple)) else (rec.get('text') if isinstance(rec, dict) else str(rec))\n",
        "                items.append({'text': text, 'bbox': _normalize_bbox(box)})\n",
        "            elif isinstance(entry, dict) and 'text' in entry and ('box' in entry or 'bbox' in entry):\n",
        "                box = entry.get('box') or entry.get('bbox')\n",
        "                items.append({'text': entry['text'], 'bbox': _normalize_bbox(box)})\n",
        "        return items\n",
        "\n",
        "    # final fallback: nothing parsed\n",
        "    return items\n",
        "\n",
        "\n",
        "def sort_into_reading_order(items: List[dict], line_threshold_factor: float = 0.6, rtl: bool = False) -> Tuple[List[str], str]:\n",
        "    \"\"\"\n",
        "    Group items into lines (top->bottom) and sort each line left->right.\n",
        "    Returns (list_of_line_texts, combined_text)\n",
        "    \"\"\"\n",
        "    if not items:\n",
        "        return [], \"\"\n",
        "\n",
        "    # compute heights and median height for thresholding\n",
        "    heights = [(it['bbox'][3] - it['bbox'][1]) for it in items]\n",
        "    median_h = statistics.median([h for h in heights if h > 0] or [10])\n",
        "\n",
        "    # compute centers and prepare sort keys\n",
        "    for it in items:\n",
        "        xmin, ymin, xmax, ymax = it['bbox']\n",
        "        it['cx'] = (xmin + xmax) / 2.0\n",
        "        it['cy'] = (ymin + ymax) / 2.0\n",
        "        it['xmin'] = xmin\n",
        "\n",
        "    # sort by vertical center (top -> bottom)\n",
        "    items_sorted_y = sorted(items, key=lambda x: x['cy'])\n",
        "\n",
        "    lines = []\n",
        "    current_line = []\n",
        "    current_line_cy = None\n",
        "\n",
        "    for it in items_sorted_y:\n",
        "        if not current_line:\n",
        "            current_line = [it]\n",
        "            current_line_cy = it['cy']\n",
        "        else:\n",
        "            if abs(it['cy'] - current_line_cy) <= median_h * line_threshold_factor:\n",
        "                current_line.append(it)\n",
        "                # update running mean center y\n",
        "                current_line_cy = (current_line_cy * (len(current_line)-1) + it['cy']) / len(current_line)\n",
        "            else:\n",
        "                lines.append(current_line)\n",
        "                current_line = [it]\n",
        "                current_line_cy = it['cy']\n",
        "    if current_line:\n",
        "        lines.append(current_line)\n",
        "\n",
        "    # within each line sort by xmin (left->right)\n",
        "    line_texts = []\n",
        "    for line in lines:\n",
        "        line_sorted = sorted(line, key=lambda x: x['xmin'], reverse=False)\n",
        "        if rtl:\n",
        "            line_sorted = list(reversed(line_sorted))\n",
        "        text_line = \" \".join([x['text'] for x in line_sorted]).strip()\n",
        "        if text_line:\n",
        "            line_texts.append(text_line)\n",
        "\n",
        "    combined = \" \".join(line_texts).strip()\n",
        "    return line_texts, combined\n",
        "\n",
        "\n",
        "\n",
        "# ------------------- Flask Application -------------------\n",
        "app = Flask(__name__)\n",
        "CORS(app) # Enable CORS for all routes\n",
        "\n",
        "@app.route('/vlm', methods=['POST'])\n",
        "def process_vlm():\n",
        "    print(\"--- INCOMING REQUEST: /vlm (Automatic Capture) ---\")\n",
        "    if not model_vlm or not yolo_model:\n",
        "        print(\"[ERROR:VLM] VLM or YOLO model not loaded. Returning 503.\")\n",
        "        return jsonify({\"caption\": \"VLM/YOLO models failed to load. Cannot process.\"}), 503\n",
        "\n",
        "    if 'file' not in request.files:\n",
        "        print(\"[ERROR:VLM] No file part found in request.\")\n",
        "        return jsonify({\"error\": \"No file part provided. Ensure the key is 'file'.\"}), 400\n",
        "\n",
        "    image_file = request.files['file']\n",
        "    print(f\"[DEBUG:VLM] Received file: {image_file.filename}\")\n",
        "\n",
        "    try:\n",
        "        img_bytes = image_file.read()\n",
        "        img = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
        "        display_image_in_colab(img.copy(), \"Original Image (VLM Mode)\")\n",
        "        print(\"[DEBUG:VLM] Image successfully loaded into PIL.\")\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR:VLM] Image read/format error: {e}\")\n",
        "        return jsonify({\"error\": \"Invalid image format\"}), 400\n",
        "\n",
        "    # 1️⃣ YOLO detection\n",
        "    objects = yolo_detect(img)\n",
        "\n",
        "    # 2️⃣ Prepare YOLO -> VLM prompt with spatial relations\n",
        "    if objects:\n",
        "        annotated_img = img.copy()\n",
        "        draw = ImageDraw.Draw(annotated_img)\n",
        "        try:\n",
        "            font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf\", 100)\n",
        "        except Exception:\n",
        "            font = ImageFont.load_default()\n",
        "\n",
        "        for obj in objects:\n",
        "            class_name = obj['name']\n",
        "            x1, y1, x2, y2 = obj['box']\n",
        "            draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=7)\n",
        "            text_pos = (x1, max(0, y1 - 35))\n",
        "            draw.text(text_pos, class_name, fill=\"red\", font=font)\n",
        "        display_image_in_colab(annotated_img, f\"YOLO Detection Output ({len(objects)} Objects)\")\n",
        "\n",
        "        objects_text = \", \".join([obj['name'] for obj in objects])\n",
        "        relations = get_relative_positions(objects)\n",
        "        relations_text = \"; \".join(relations)\n",
        "\n",
        "        prompt_text = (\n",
        "            f\"Objects: {objects_text}. \"\n",
        "            f\"Relations: {relations_text}. \"\n",
        "            f\"Describe the scene for a visually impaired person in one concise sentence.\"\n",
        "        )\n",
        "        print(\"-----\")\n",
        "        print(f\"Objects detected : {objects_text} and their respective relation positioins {relations_text}\")\n",
        "        print(\"-----\")\n",
        "\n",
        "    else:\n",
        "        prompt_text = \"Briefly describe the scene in natural language for a visually impaired person in one concise sentence.\"\n",
        "        print(\"[DEBUG:VLM] No objects detected. Using generic VLM prompt.\")\n",
        "\n",
        "\n",
        "    # 3️⃣ VLM caption with spatial awareness (English)\n",
        "    caption_en = vlm_caption(img, prompt_text)\n",
        "    print(f\"[DEBUG:VLM] Final English Caption: {caption_en}\")\n",
        "\n",
        "\n",
        "    # 4️⃣ TRANSLATION STEP (English -> Indic Language)\n",
        "    translated_caption = f\"Translation to {TARGET_LANG_NAME} failed or model is unavailable.\"\n",
        "    if en_indic_model and caption_en not in [\"VLM model is unavailable.\", \"Error analyzing image.\"]:\n",
        "        try:\n",
        "            print(f\"[DEBUG:MT] Starting translation to {TARGET_LANG_NAME} ({TARGET_LANG_CODE})...\")\n",
        "            translation_results = batch_translate(\n",
        "                [caption_en], SOURCE_LANG_CODE, TARGET_LANG_CODE,\n",
        "                en_indic_model, en_indic_tokenizer, indic_processor\n",
        "            )\n",
        "            translated_caption = translation_results[0]\n",
        "            print(f\"[DEBUG:MT] Translated Caption: {translated_caption}\")\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR:MT] Translation failed: {e}\")\n",
        "            translated_caption = f\"Translation error: {e}\"\n",
        "\n",
        "    # 5️⃣ Return the results as a JSON object\n",
        "    return jsonify({\n",
        "        \"caption\": caption_en,\n",
        "        \"translated_caption\": translated_caption,\n",
        "        \"target_language\": TARGET_LANG_NAME,\n",
        "        \"yolo_objects\": objects,\n",
        "        \"vlm_prompt\": prompt_text\n",
        "    })\n",
        "\n",
        "@app.route('/ocr', methods=['POST'])\n",
        "def process_ocr():\n",
        "    \"\"\"Route for OCR processing (Manual Capture) using PaddleOCR.\"\"\"\n",
        "    print(\"--- INCOMING REQUEST: /ocr (Manual Capture) ---\")\n",
        "\n",
        "    if not ocr_model:\n",
        "        print(\"[ERROR:OCR] OCR model not loaded. Returning 503.\")\n",
        "        return jsonify({\"caption\": \"OCR model failed to load. Cannot process.\"}), 503\n",
        "\n",
        "    if 'file' not in request.files:\n",
        "        print(\"[ERROR:OCR] No file part found in request.\")\n",
        "        return jsonify({\"error\": \"No file part provided.\"}), 400\n",
        "\n",
        "    image_file = request.files['file']\n",
        "    print(f\"[DEBUG:OCR] Received file: {image_file.filename}\")\n",
        "\n",
        "    temp_file_path = None\n",
        "    full_text = \"\"\n",
        "    ocr_texts = []\n",
        "\n",
        "    try:\n",
        "        # --- Read image and save temp file ---\n",
        "        img_bytes = image_file.read()\n",
        "        img = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
        "        print(\"[DEBUG:OCR] Image successfully loaded into PIL.\")\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(suffix=\".png\", delete=False) as tmp:\n",
        "            temp_file_path = tmp.name\n",
        "            img.save(temp_file_path)\n",
        "        print(f\"[DEBUG:OCR] Image temporarily saved to: {temp_file_path}\")\n",
        "\n",
        "        # --- Run PaddleOCR ---\n",
        "        result = ocr_model.predict(temp_file_path)\n",
        "        for res in result:\n",
        "          res.print()\n",
        "          res.save_to_img(\"output\")\n",
        "        print(f\"[DEBUG:OCR] Raw OCR result type: {type(result)}\")\n",
        "        print(f\"detected :{result[0]['rec_texts']}\")\n",
        "        # print raw result length for debugging\n",
        "        try:\n",
        "            print(f\"[DEBUG:OCR] Raw OCR result preview: {str(result)[:400]}\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # --- Parse and reorder results into human reading order ---\n",
        "        items = _parse_paddle_result(result)\n",
        "        # If you OCR multi-column documents, you may need a more advanced column detector.\n",
        "        LINE_THRESHOLD_FACTOR = 0.6  # tweak if lines are merged/split incorrectly\n",
        "        rtl_mode = False  # set True for RTL languages (Arabic/Hebrew). Could add auto-detection later.\n",
        "\n",
        "        if not items:\n",
        "            # fallback: try the old quick extraction for compatibility\n",
        "            ocr_texts = []\n",
        "            if isinstance(result, list) and len(result) > 0:\n",
        "                # Case 1: PaddleOCR >= 2.7 structured dict output\n",
        "                if isinstance(result[0], dict) and 'rec_texts' in result[0]:\n",
        "                    ocr_texts = result[0]['rec_texts']\n",
        "                # Case 2: Legacy nested list format [[box, [text, conf]], ...]\n",
        "                elif isinstance(result[0], list) and len(result[0]) > 0:\n",
        "                    page_result = result[0]\n",
        "                    for line_data in page_result:\n",
        "                        if not (isinstance(line_data, list) and len(line_data) >= 2):\n",
        "                            continue\n",
        "                        text = line_data[1][0]\n",
        "                        ocr_texts.append(text)\n",
        "            full_text = \" \".join(ocr_texts).strip()\n",
        "        else:\n",
        "            ocr_lines, full_text = sort_into_reading_order(items, LINE_THRESHOLD_FACTOR, rtl=rtl_mode)\n",
        "            ocr_texts = ocr_lines\n",
        "\n",
        "        caption = f\"The text detected in the image is: {full_text or 'No text detected.'}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[OCR Error]: {e}\")\n",
        "        caption = f\"An error occurred during OCR processing: {e}\"\n",
        "\n",
        "    finally:\n",
        "        if temp_file_path and os.path.exists(temp_file_path):\n",
        "            os.remove(temp_file_path)\n",
        "            print(f\"[DEBUG:OCR] Cleaned up temporary file.\")\n",
        "\n",
        "    # --- Send response to frontend ---\n",
        "    print(\"[OCR RESULTS :]\",ocr_texts)\n",
        "    print(\"[OCR RESULTS COMBINED:]\",full_text)\n",
        "    return jsonify({\n",
        "        \"caption\": caption,\n",
        "        \"ocr_results\": ocr_texts,\n",
        "        \"ocr_result_combined\": full_text\n",
        "    })\n",
        "\n",
        "\n",
        "# ------------------- Run Flask with ngrok -------------------\n",
        "from pyngrok import ngrok\n",
        "\n",
        "PORT = 5000\n",
        "\n",
        "# Put your ngrok authtoken here (copy it from https://dashboard.ngrok.com/get-started/your-authtoken)\n",
        "from google.colab import userdata\n",
        "\n",
        "NGROK_TOKEN = userdata.get('ngork')\n",
        "\n",
        "# Kill any leftover ngrok processes first (optional but useful)\n",
        "try:\n",
        "    ngrok.kill()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Set the token\n",
        "try:\n",
        "    ngrok.set_auth_token(NGROK_TOKEN)\n",
        "    print(\"✅ ngrok auth token set.\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Failed to set ngrok auth token: {e}\")\n",
        "    print(\"If running in Colab, consider storing the token in Colab Secrets and reading it instead.\")\n",
        "\n",
        "# Debug summary\n",
        "print(\"\\n--- Model Load Summary ---\")\n",
        "print(f\"SmolVLM2 (VLM): {'LOADED' if model_vlm else 'FAILED'}\")\n",
        "print(f\"YOLOv8n (Detection): {'LOADED' if yolo_model else 'FAILED'}\")\n",
        "print(f\"PaddleOCR (OCR): {'LOADED' if ocr_model else 'FAILED'}\")\n",
        "print(f\"IndicTrans2 (MT): {'LOADED' if en_indic_model else 'FAILED'}\")\n",
        "print(f\"Target Language: {TARGET_LANG_NAME} ({TARGET_LANG_CODE})\")\n",
        "print(\"--------------------------\\n\")\n",
        "\n",
        "# Try to open the tunnel and run Flask\n",
        "try:\n",
        "    public_url = ngrok.connect(PORT)\n",
        "    public_url_str = public_url.public_url if public_url else None\n",
        "\n",
        "    if public_url_str:\n",
        "        print(f\"* Flask app running on port {PORT}\")\n",
        "        print(f\"* Public URL: {public_url_str}\")\n",
        "        print(f\"Set your mobile app BASE_FLASK_API_URL to: {public_url_str}\")\n",
        "    else:\n",
        "        print(f\"* Flask app running on port {PORT} (no public ngrok URL)\")\n",
        "\n",
        "    if __name__ == '__main__':\n",
        "        app.run(port=PORT, debug=True, use_reloader=False)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"\\n[NGROK/FLASK ERROR]: Could not start server or ngrok tunnel.\")\n",
        "    print(f\"Error details: {e}\")\n",
        "    print(\"\\nHints:\")\n",
        "    print(\"- Make sure you pasted a valid token (not revoked).\")\n",
        "    print(\"- If you have another active tunnel under same account, stop it first.\")\n",
        "    print(\"- For long-term runs use ngrok CLI locally: `ngrok authtoken <token>` then `ngrok http 5000`.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85xzKF235DoF",
        "outputId": "b21c45bc-9fc4-4030-dfac-38a040f5bb62"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing models...\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1912579332.py:203: DeprecationWarning: The parameter `use_angle_cls` has been deprecated and will be removed in the future. Please use `use_textline_orientation` instead.\n",
            "  ocr_model = PaddleOCR(use_angle_cls=True, lang=\"en\")\n",
            "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
            "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/root/.paddlex/official_models/PP-LCNet_x1_0_doc_ori`.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SmolVLM2 loaded.\n",
            "YOLO model loaded.\n",
            "Loading PaddleOCR...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
            "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/root/.paddlex/official_models/UVDoc`.\u001b[0m\n",
            "\u001b[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001b[0m\n",
            "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/root/.paddlex/official_models/PP-LCNet_x1_0_textline_ori`.\u001b[0m\n",
            "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
            "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/root/.paddlex/official_models/PP-OCRv5_server_det`.\u001b[0m\n",
            "\u001b[32mCreating model: ('en_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
            "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/root/.paddlex/official_models/en_PP-OCRv5_mobile_rec`.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PaddleOCR loaded.\n",
            "Loading IndicTrans2 model...\n",
            "IndicTrans2 loaded for translation to kannada.\n",
            "✅ ngrok auth token set.\n",
            "\n",
            "--- Model Load Summary ---\n",
            "SmolVLM2 (VLM): LOADED\n",
            "YOLOv8n (Detection): LOADED\n",
            "PaddleOCR (OCR): LOADED\n",
            "IndicTrans2 (MT): LOADED\n",
            "Target Language: kannada (kan_Knda)\n",
            "--------------------------\n",
            "\n",
            "* Flask app running on port 5000\n",
            "* Public URL: https://d4b640e54324.ngrok-free.app\n",
            "Set your mobile app BASE_FLASK_API_URL to: https://d4b640e54324.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- INCOMING REQUEST: /ocr (Manual Capture) ---\n",
            "[DEBUG:OCR] Received file: 56574d02-1c84-4fe7-9e2f-0425151d5125.jpg\n",
            "[DEBUG:OCR] Image successfully loaded into PIL.\n",
            "[DEBUG:OCR] Image temporarily saved to: /tmp/tmpttqm8j9d.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m{'res': {'input_path': '/tmp/tmpttqm8j9d.png', 'page_index': None, 'model_settings': {'use_doc_preprocessor': True, 'use_textline_orientation': True}, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'model_settings': {'use_doc_orientation_classify': True, 'use_doc_unwarping': True}, 'angle': 0}, 'dt_polys': array([], dtype=float64), 'text_det_params': {'limit_side_len': 64, 'limit_type': 'min', 'thresh': 0.3, 'max_side_limit': 4000, 'box_thresh': 0.6, 'unclip_ratio': 1.5}, 'text_type': 'general', 'text_rec_score_thresh': 0.0, 'return_word_box': False, 'rec_texts': [], 'rec_scores': array([], dtype=float64), 'rec_polys': array([], dtype=float64), 'rec_boxes': array([], dtype=float64)}}\u001b[0m\n",
            "Connecting to https://paddle-model-ecology.bj.bcebos.com/paddlex/PaddleX3.0/fonts/PingFang-SC-Regular.ttf ...\n",
            "Downloading PingFang-SC-Regular.ttf ...\n",
            "[==================================================] 100.00%\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 08:14:11] \"POST /ocr HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG:OCR] Raw OCR result type: <class 'list'>\n",
            "detected :[]\n",
            "[DEBUG:OCR] Raw OCR result preview: [{'input_path': '/tmp/tmpttqm8j9d.png', 'page_index': None, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'input_img': array([[[ 0, ...,  0],\n",
            "        ...,\n",
            "        [ 0, ...,  1]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 5, ...,  4],\n",
            "        ...,\n",
            "        [ 6, ..., 10]]], shape=(3000, 4000, 3), dtype=uint8), 'model_settings': {'use_doc_orientation_classify': True, 'use_doc_unwarping': True}, 'angl\n",
            "[DEBUG:OCR] Cleaned up temporary file.\n",
            "[OCR RESULTS :] []\n",
            "[OCR RESULTS COMBINED:] \n",
            "--- INCOMING REQUEST: /ocr (Manual Capture) ---\n",
            "[DEBUG:OCR] Received file: 4f851cc1-d53e-4013-a7c9-b739e6c70e0e.jpg\n",
            "[DEBUG:OCR] Image successfully loaded into PIL.\n",
            "[DEBUG:OCR] Image temporarily saved to: /tmp/tmpcfwo_waz.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m{'res': {'input_path': '/tmp/tmpcfwo_waz.png', 'page_index': None, 'model_settings': {'use_doc_preprocessor': True, 'use_textline_orientation': True}, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'model_settings': {'use_doc_orientation_classify': True, 'use_doc_unwarping': True}, 'angle': 0}, 'dt_polys': array([], dtype=float64), 'text_det_params': {'limit_side_len': 64, 'limit_type': 'min', 'thresh': 0.3, 'max_side_limit': 4000, 'box_thresh': 0.6, 'unclip_ratio': 1.5}, 'text_type': 'general', 'text_rec_score_thresh': 0.0, 'return_word_box': False, 'rec_texts': [], 'rec_scores': array([], dtype=float64), 'rec_polys': array([], dtype=float64), 'rec_boxes': array([], dtype=float64)}}\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 08:15:12] \"POST /ocr HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG:OCR] Raw OCR result type: <class 'list'>\n",
            "detected :[]\n",
            "[DEBUG:OCR] Raw OCR result preview: [{'input_path': '/tmp/tmpcfwo_waz.png', 'page_index': None, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'input_img': array([[[0, ..., 0],\n",
            "        ...,\n",
            "        [2, ..., 4]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[4, ..., 4],\n",
            "        ...,\n",
            "        [3, ..., 5]]], shape=(3000, 4000, 3), dtype=uint8), 'model_settings': {'use_doc_orientation_classify': True, 'use_doc_unwarping': True}, 'angle': 0, '\n",
            "[DEBUG:OCR] Cleaned up temporary file.\n",
            "[OCR RESULTS :] []\n",
            "[OCR RESULTS COMBINED:] \n",
            "--- INCOMING REQUEST: /ocr (Manual Capture) ---\n",
            "[DEBUG:OCR] Received file: e55145d1-d0a7-4f97-821b-bea886851c24.jpg\n",
            "[DEBUG:OCR] Image successfully loaded into PIL.\n",
            "[DEBUG:OCR] Image temporarily saved to: /tmp/tmpje0r1ti6.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m{'res': {'input_path': '/tmp/tmpje0r1ti6.png', 'page_index': None, 'model_settings': {'use_doc_preprocessor': True, 'use_textline_orientation': True}, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'model_settings': {'use_doc_orientation_classify': True, 'use_doc_unwarping': True}, 'angle': 0}, 'dt_polys': array([[[2755,  107],\n",
            "        ...,\n",
            "        [2755,  138]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[3333, 2903],\n",
            "        ...,\n",
            "        [3333, 2908]]], shape=(39, 4, 2), dtype=int16), 'text_det_params': {'limit_side_len': 64, 'limit_type': 'min', 'thresh': 0.3, 'max_side_limit': 4000, 'box_thresh': 0.6, 'unclip_ratio': 1.5}, 'text_type': 'general', 'textline_orientation_angles': array([0, ..., 1], shape=(39,)), 'text_rec_score_thresh': 0.0, 'return_word_box': False, 'rec_texts': ['C', '[0,', '1]].', '[[ 5,', '4],', '.', '[DEBUG:OCR] Cleaned up temporary file.', '[OCR RESULTS :] []', '[OCR RESULTS COMBINED:]', 'INCOMING REQUEST: /oCr (Manua1 Capture)', '[DEBUG:0CR] Received file: 4f851cc1-d53e-4013-a7c9-b739e6c70e0e.jpg', 'TDEBUG:OCR', 'Image successfully loaded into PIL.', '[DEBuG:OcR] Image temporarily saved to: /tmp/tmpcfwo_waz.png', 'model_settings\": {\\'u', '{\\'res\\': {\\'input_path\\':\\'/tmp/tmpcfwo_waz.png\",\"pageindex\\':None,', '[25/0ct/202508:15:12]\"P0ST /0CrHTTP/1.1\"260', 'INF0:werkzeug:127.0.0.1-', '[DEBuG:OcR] Raw OCR result type:<classlist\">', 'detected:[', 'pageindex', '[DEBuG:ocR] Raw OcR resuIt preview: [C inputpath /tmp/tmpcfwo_waz.png', '33', '2, . .., 4]],', '[[4,', '..', '7', '5111-5hape-C30ea0o03tpe-u1nt8.', 'DopTesn.] EsButestepou', '[3,', 'FFEF', '[DEBUG:OCR] Cleaned up temporar tie', '[OCR RESULTS E] ]', '[OCR RESULTS COMBINEDE]', '', 'Show code', '', '', '-'], 'rec_scores': array([0.46359435, ..., 0.68080628], shape=(39,)), 'rec_polys': array([[[2755,  107],\n",
            "        ...,\n",
            "        [2755,  138]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[3333, 2903],\n",
            "        ...,\n",
            "        [3333, 2908]]], shape=(39, 4, 2), dtype=int16), 'rec_boxes': array([[2755, ...,  138],\n",
            "       ...,\n",
            "       [3333, ..., 2908]], shape=(39, 4), dtype=int16)}}\u001b[0m\n",
            "Connecting to https://paddle-model-ecology.bj.bcebos.com/paddlex/PaddleX3.0/fonts/simfang.ttf ...\n",
            "Downloading simfang.ttf ...\n",
            "[==================================================] 100.00%\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 08:16:28] \"POST /ocr HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG:OCR] Raw OCR result type: <class 'list'>\n",
            "detected :['C', '[0,', '1]].', '[[ 5,', '4],', '.', '[DEBUG:OCR] Cleaned up temporary file.', '[OCR RESULTS :] []', '[OCR RESULTS COMBINED:]', 'INCOMING REQUEST: /oCr (Manua1 Capture)', '[DEBUG:0CR] Received file: 4f851cc1-d53e-4013-a7c9-b739e6c70e0e.jpg', 'TDEBUG:OCR', 'Image successfully loaded into PIL.', '[DEBuG:OcR] Image temporarily saved to: /tmp/tmpcfwo_waz.png', 'model_settings\": {\\'u', '{\\'res\\': {\\'input_path\\':\\'/tmp/tmpcfwo_waz.png\",\"pageindex\\':None,', '[25/0ct/202508:15:12]\"P0ST /0CrHTTP/1.1\"260', 'INF0:werkzeug:127.0.0.1-', '[DEBuG:OcR] Raw OCR result type:<classlist\">', 'detected:[', 'pageindex', '[DEBuG:ocR] Raw OcR resuIt preview: [C inputpath /tmp/tmpcfwo_waz.png', '33', '2, . .., 4]],', '[[4,', '..', '7', '5111-5hape-C30ea0o03tpe-u1nt8.', 'DopTesn.] EsButestepou', '[3,', 'FFEF', '[DEBUG:OCR] Cleaned up temporar tie', '[OCR RESULTS E] ]', '[OCR RESULTS COMBINEDE]', '', 'Show code', '', '', '-']\n",
            "[DEBUG:OCR] Raw OCR result preview: [{'input_path': '/tmp/tmpje0r1ti6.png', 'page_index': None, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'input_img': array([[[ 95, ..., 112],\n",
            "        ...,\n",
            "        [ 29, ...,  49]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 88, ..., 124],\n",
            "        ...,\n",
            "        [ 24, ...,  13]]], shape=(3000, 4000, 3), dtype=uint8), 'model_settings': {'use_doc_orientation_classify': True, 'use_doc_unwarping': True\n",
            "[DEBUG:OCR] Cleaned up temporary file.\n",
            "[OCR RESULTS :] ['C [0, 1]]. [[ 5, 4], . [DEBUG:OCR] Cleaned up temporary file. [OCR RESULTS :] [] [OCR RESULTS COMBINED:] INCOMING REQUEST: /oCr (Manua1 Capture) [DEBUG:0CR] Received file: 4f851cc1-d53e-4013-a7c9-b739e6c70e0e.jpg TDEBUG:OCR Image successfully loaded into PIL. [DEBuG:OcR] Image temporarily saved to: /tmp/tmpcfwo_waz.png model_settings\": {\\'u {\\'res\\': {\\'input_path\\':\\'/tmp/tmpcfwo_waz.png\",\"pageindex\\':None, [25/0ct/202508:15:12]\"P0ST /0CrHTTP/1.1\"260 INF0:werkzeug:127.0.0.1- [DEBuG:OcR] Raw OCR result type:<classlist\"> detected:[ pageindex [DEBuG:ocR] Raw OcR resuIt preview: [C inputpath /tmp/tmpcfwo_waz.png 33 2, . .., 4]], [[4, .. 7 5111-5hape-C30ea0o03tpe-u1nt8. DopTesn.] EsButestepou [3, FFEF [DEBUG:OCR] Cleaned up temporar tie [OCR RESULTS E] ] [OCR RESULTS COMBINEDE]  Show code   -']\n",
            "[OCR RESULTS COMBINED:] C [0, 1]]. [[ 5, 4], . [DEBUG:OCR] Cleaned up temporary file. [OCR RESULTS :] [] [OCR RESULTS COMBINED:] INCOMING REQUEST: /oCr (Manua1 Capture) [DEBUG:0CR] Received file: 4f851cc1-d53e-4013-a7c9-b739e6c70e0e.jpg TDEBUG:OCR Image successfully loaded into PIL. [DEBuG:OcR] Image temporarily saved to: /tmp/tmpcfwo_waz.png model_settings\": {'u {'res': {'input_path':'/tmp/tmpcfwo_waz.png\",\"pageindex':None, [25/0ct/202508:15:12]\"P0ST /0CrHTTP/1.1\"260 INF0:werkzeug:127.0.0.1- [DEBuG:OcR] Raw OCR result type:<classlist\"> detected:[ pageindex [DEBuG:ocR] Raw OcR resuIt preview: [C inputpath /tmp/tmpcfwo_waz.png 33 2, . .., 4]], [[4, .. 7 5111-5hape-C30ea0o03tpe-u1nt8. DopTesn.] EsButestepou [3, FFEF [DEBUG:OCR] Cleaned up temporar tie [OCR RESULTS E] ] [OCR RESULTS COMBINEDE]  Show code   -\n",
            "--- INCOMING REQUEST: /ocr (Manual Capture) ---\n",
            "[DEBUG:OCR] Received file: 71ca0a87-85c6-4fbd-83c4-9fe6ba85af06.jpg\n",
            "[DEBUG:OCR] Image successfully loaded into PIL.\n",
            "[DEBUG:OCR] Image temporarily saved to: /tmp/tmp0fl_f6nl.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m{'res': {'input_path': '/tmp/tmp0fl_f6nl.png', 'page_index': None, 'model_settings': {'use_doc_preprocessor': True, 'use_textline_orientation': True}, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'model_settings': {'use_doc_orientation_classify': True, 'use_doc_unwarping': True}, 'angle': 0}, 'dt_polys': array([], dtype=float64), 'text_det_params': {'limit_side_len': 64, 'limit_type': 'min', 'thresh': 0.3, 'max_side_limit': 4000, 'box_thresh': 0.6, 'unclip_ratio': 1.5}, 'text_type': 'general', 'text_rec_score_thresh': 0.0, 'return_word_box': False, 'rec_texts': [], 'rec_scores': array([], dtype=float64), 'rec_polys': array([], dtype=float64), 'rec_boxes': array([], dtype=float64)}}\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 08:17:17] \"POST /ocr HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG:OCR] Raw OCR result type: <class 'list'>\n",
            "detected :[]\n",
            "[DEBUG:OCR] Raw OCR result preview: [{'input_path': '/tmp/tmp0fl_f6nl.png', 'page_index': None, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'input_img': array([[[ 8, ..., 13],\n",
            "        ...,\n",
            "        [10, ...,  7]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 3, ...,  2],\n",
            "        ...,\n",
            "        [13, ..., 13]]], shape=(3000, 4000, 3), dtype=uint8), 'model_settings': {'use_doc_orientation_classify': True, 'use_doc_unwarping': True}, 'angl\n",
            "[DEBUG:OCR] Cleaned up temporary file.\n",
            "[OCR RESULTS :] []\n",
            "[OCR RESULTS COMBINED:] \n",
            "--- INCOMING REQUEST: /ocr (Manual Capture) ---\n",
            "[DEBUG:OCR] Received file: e792255f-4718-4482-b63d-df190db1b5a4.jpg\n",
            "[DEBUG:OCR] Image successfully loaded into PIL.\n",
            "[DEBUG:OCR] Image temporarily saved to: /tmp/tmphif17xms.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m{'res': {'input_path': '/tmp/tmphif17xms.png', 'page_index': None, 'model_settings': {'use_doc_preprocessor': True, 'use_textline_orientation': True}, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'model_settings': {'use_doc_orientation_classify': True, 'use_doc_unwarping': True}, 'angle': 0}, 'dt_polys': array([[[ 202,  302],\n",
            "        ...,\n",
            "        [ 149,  624]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 367, 2466],\n",
            "        ...,\n",
            "        [ 367, 2605]]], shape=(31, 4, 2), dtype=int16), 'text_det_params': {'limit_side_len': 64, 'limit_type': 'min', 'thresh': 0.3, 'max_side_limit': 4000, 'box_thresh': 0.6, 'unclip_ratio': 1.5}, 'text_type': 'general', 'textline_orientation_angles': array([0, ..., 0], shape=(31,)), 'text_rec_score_thresh': 0.0, 'return_word_box': False, 'rec_texts': ['@N', '# 3', 'S4', '%', '9>', '∞N', '* ∞', '5', '9', 'E', 'R', 'T', 'Y', 'U', 'O', '4s', 'E', 'G', 'H', 'J', 'K', 'L', 'Ix', 'Z', 'C', 'V', 'B', 'N', 'M', '<', 'Alt'], 'rec_scores': array([0.56115675, ..., 0.99602056], shape=(31,)), 'rec_polys': array([[[ 202,  302],\n",
            "        ...,\n",
            "        [ 149,  624]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 367, 2466],\n",
            "        ...,\n",
            "        [ 367, 2605]]], shape=(31, 4, 2), dtype=int16), 'rec_boxes': array([[ 149, ...,  651],\n",
            "       ...,\n",
            "       [ 367, ..., 2605]], shape=(31, 4), dtype=int16)}}\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 08:17:56] \"POST /ocr HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG:OCR] Raw OCR result type: <class 'list'>\n",
            "detected :['@N', '# 3', 'S4', '%', '9>', '∞N', '* ∞', '5', '9', 'E', 'R', 'T', 'Y', 'U', 'O', '4s', 'E', 'G', 'H', 'J', 'K', 'L', 'Ix', 'Z', 'C', 'V', 'B', 'N', 'M', '<', 'Alt']\n",
            "[DEBUG:OCR] Raw OCR result preview: [{'input_path': '/tmp/tmphif17xms.png', 'page_index': None, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'input_img': array([[[ 33, ...,  20],\n",
            "        ...,\n",
            "        [ 71, ...,  90]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 72, ..., 136],\n",
            "        ...,\n",
            "        [ 16, ...,  10]]], shape=(3000, 4000, 3), dtype=uint8), 'model_settings': {'use_doc_orientation_classify': True, 'use_doc_unwarping': True\n",
            "[DEBUG:OCR] Cleaned up temporary file.\n",
            "[OCR RESULTS :] ['@N # 3 S4 % 9> ∞N * ∞ 5 9 E R T Y U O 4s E G H J K L Ix Z C V B N M < Alt']\n",
            "[OCR RESULTS COMBINED:] @N # 3 S4 % 9> ∞N * ∞ 5 9 E R T Y U O 4s E G H J K L Ix Z C V B N M < Alt\n",
            "--- INCOMING REQUEST: /ocr (Manual Capture) ---\n",
            "[DEBUG:OCR] Received file: d67d72fe-cf37-426f-aae4-d740a5266afd.jpg\n",
            "[DEBUG:OCR] Image successfully loaded into PIL.\n",
            "[DEBUG:OCR] Image temporarily saved to: /tmp/tmp7fe9rh66.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m{'res': {'input_path': '/tmp/tmp7fe9rh66.png', 'page_index': None, 'model_settings': {'use_doc_preprocessor': True, 'use_textline_orientation': True}, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'model_settings': {'use_doc_orientation_classify': True, 'use_doc_unwarping': True}, 'angle': 90}, 'dt_polys': array([[[2121,  524],\n",
            "        ...,\n",
            "        [2123,  670]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 387, 2822],\n",
            "        ...,\n",
            "        [ 384, 2917]]], shape=(13, 4, 2), dtype=int16), 'text_det_params': {'limit_side_len': 64, 'limit_type': 'min', 'thresh': 0.3, 'max_side_limit': 4000, 'box_thresh': 0.6, 'unclip_ratio': 1.5}, 'text_type': 'general', 'textline_orientation_angles': array([1, ..., 0], shape=(13,)), 'text_rec_score_thresh': 0.0, 'return_word_box': False, 'rec_texts': ['|s  ', '', 'BGSKH Education Trust . A unit of Sri Adichunchanagiri Shikshana Trust 8.', 'BGS COLLEGE OF ENGINEERING', 'G AND TECHNOLOGY', '(Approved by AICTE-New Delhi, affiliated to VTU, Belagavi)', 'CA Se No. 6 &  3rd Main, Pipeline Road,  Phase,  Stage, Aj. Mahalakshmi Metr Staton', 'West of Chord Road, Mahalakshmipuram, Bengaluru - 560086. Karnataka', 'ASSESSMENT BOOK', 'Name', 'USN', 'Semester', 'Branch'], 'rec_scores': array([0.4090369 , ..., 0.99972528], shape=(13,)), 'rec_polys': array([[[2121,  524],\n",
            "        ...,\n",
            "        [2123,  670]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 387, 2822],\n",
            "        ...,\n",
            "        [ 384, 2917]]], shape=(13, 4, 2), dtype=int16), 'rec_boxes': array([[2121, ...,  670],\n",
            "       ...,\n",
            "       [ 384, ..., 2924]], shape=(13, 4), dtype=int16)}}\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 08:18:39] \"POST /ocr HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG:OCR] Raw OCR result type: <class 'list'>\n",
            "detected :['|s  ', '', 'BGSKH Education Trust . A unit of Sri Adichunchanagiri Shikshana Trust 8.', 'BGS COLLEGE OF ENGINEERING', 'G AND TECHNOLOGY', '(Approved by AICTE-New Delhi, affiliated to VTU, Belagavi)', 'CA Se No. 6 &  3rd Main, Pipeline Road,  Phase,  Stage, Aj. Mahalakshmi Metr Staton', 'West of Chord Road, Mahalakshmipuram, Bengaluru - 560086. Karnataka', 'ASSESSMENT BOOK', 'Name', 'USN', 'Semester', 'Branch']\n",
            "[DEBUG:OCR] Raw OCR result preview: [{'input_path': '/tmp/tmp7fe9rh66.png', 'page_index': None, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'input_img': array([[[ 28, ...,  71],\n",
            "        ...,\n",
            "        [ 21, ...,  55]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 48, ..., 153],\n",
            "        ...,\n",
            "        [184, ..., 168]]], shape=(4000, 3000, 3), dtype=uint8), 'model_settings': {'use_doc_orientation_classify': True, 'use_doc_unwarping': True\n",
            "[DEBUG:OCR] Cleaned up temporary file.\n",
            "[OCR RESULTS :] ['|s    BGSKH Education Trust . A unit of Sri Adichunchanagiri Shikshana Trust 8. BGS COLLEGE OF ENGINEERING G AND TECHNOLOGY (Approved by AICTE-New Delhi, affiliated to VTU, Belagavi) CA Se No. 6 &  3rd Main, Pipeline Road,  Phase,  Stage, Aj. Mahalakshmi Metr Staton West of Chord Road, Mahalakshmipuram, Bengaluru - 560086. Karnataka ASSESSMENT BOOK Name USN Semester Branch']\n",
            "[OCR RESULTS COMBINED:] |s    BGSKH Education Trust . A unit of Sri Adichunchanagiri Shikshana Trust 8. BGS COLLEGE OF ENGINEERING G AND TECHNOLOGY (Approved by AICTE-New Delhi, affiliated to VTU, Belagavi) CA Se No. 6 &  3rd Main, Pipeline Road,  Phase,  Stage, Aj. Mahalakshmi Metr Staton West of Chord Road, Mahalakshmipuram, Bengaluru - 560086. Karnataka ASSESSMENT BOOK Name USN Semester Branch\n",
            "--- INCOMING REQUEST: /ocr (Manual Capture) ---\n",
            "[DEBUG:OCR] Received file: 0870fe82-c6a6-434c-b855-0b31c219d110.jpg\n",
            "[DEBUG:OCR] Image successfully loaded into PIL.\n",
            "[DEBUG:OCR] Image temporarily saved to: /tmp/tmp3h_4ml66.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m{'res': {'input_path': '/tmp/tmp3h_4ml66.png', 'page_index': None, 'model_settings': {'use_doc_preprocessor': True, 'use_textline_orientation': True}, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'model_settings': {'use_doc_orientation_classify': True, 'use_doc_unwarping': True}, 'angle': 0}, 'dt_polys': array([], dtype=float64), 'text_det_params': {'limit_side_len': 64, 'limit_type': 'min', 'thresh': 0.3, 'max_side_limit': 4000, 'box_thresh': 0.6, 'unclip_ratio': 1.5}, 'text_type': 'general', 'text_rec_score_thresh': 0.0, 'return_word_box': False, 'rec_texts': [], 'rec_scores': array([], dtype=float64), 'rec_polys': array([], dtype=float64), 'rec_boxes': array([], dtype=float64)}}\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 08:19:51] \"POST /ocr HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG:OCR] Raw OCR result type: <class 'list'>\n",
            "detected :[]\n",
            "[DEBUG:OCR] Raw OCR result preview: [{'input_path': '/tmp/tmp3h_4ml66.png', 'page_index': None, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'input_img': array([[[75, ..., 83],\n",
            "        ...,\n",
            "        [41, ..., 48]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[10, ...,  4],\n",
            "        ...,\n",
            "        [14, ...,  2]]], shape=(4000, 3000, 3), dtype=uint8), 'model_settings': {'use_doc_orientation_classify': True, 'use_doc_unwarping': True}, 'angl\n",
            "[DEBUG:OCR] Cleaned up temporary file.\n",
            "[OCR RESULTS :] []\n",
            "[OCR RESULTS COMBINED:] \n",
            "--- INCOMING REQUEST: /ocr (Manual Capture) ---\n",
            "[DEBUG:OCR] Received file: 47399d2e-19be-4592-971f-ccb8883cdc40.jpg\n",
            "[DEBUG:OCR] Image successfully loaded into PIL.\n",
            "[DEBUG:OCR] Image temporarily saved to: /tmp/tmpdv21bv6j.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m{'res': {'input_path': '/tmp/tmpdv21bv6j.png', 'page_index': None, 'model_settings': {'use_doc_preprocessor': True, 'use_textline_orientation': True}, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'model_settings': {'use_doc_orientation_classify': True, 'use_doc_unwarping': True}, 'angle': 90}, 'dt_polys': array([[[2164,   69],\n",
            "        ...,\n",
            "        [2161,  218]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 774, 2290],\n",
            "        ...,\n",
            "        [ 775, 2411]]], shape=(12, 4, 2), dtype=int16), 'text_det_params': {'limit_side_len': 64, 'limit_type': 'min', 'thresh': 0.3, 'max_side_limit': 4000, 'box_thresh': 0.6, 'unclip_ratio': 1.5}, 'text_type': 'general', 'textline_orientation_angles': array([0, ..., 0], shape=(12,)), 'text_rec_score_thresh': 0.0, 'return_word_box': False, 'rec_texts': ['Vision', 'Creating Competent IT Professionals with Core Values', 'for the real world\"', 'Mission', 'Providing Students with a Sound Knowledge in IT Fundamentals.', 'Exposing Students to Emerging Frontiers in various domains of IT', 'enabling Continuous Learning.', 'Promoting Excellence in Teaching, Training, Research and Consultancy.', 'Developing Entrepreneurial acumen to venture into Innovative areas of', 'IT.', 'Imparting value based Professional Education with a sense of Social', 'Responsibility.'], 'rec_scores': array([0.99951845, ..., 0.99725288], shape=(12,)), 'rec_polys': array([[[2164,   69],\n",
            "        ...,\n",
            "        [2161,  218]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 774, 2290],\n",
            "        ...,\n",
            "        [ 775, 2411]]], shape=(12, 4, 2), dtype=int16), 'rec_boxes': array([[2161, ...,  224],\n",
            "       ...,\n",
            "       [ 774, ..., 2411]], shape=(12, 4), dtype=int16)}}\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 08:20:26] \"POST /ocr HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG:OCR] Raw OCR result type: <class 'list'>\n",
            "detected :['Vision', 'Creating Competent IT Professionals with Core Values', 'for the real world\"', 'Mission', 'Providing Students with a Sound Knowledge in IT Fundamentals.', 'Exposing Students to Emerging Frontiers in various domains of IT', 'enabling Continuous Learning.', 'Promoting Excellence in Teaching, Training, Research and Consultancy.', 'Developing Entrepreneurial acumen to venture into Innovative areas of', 'IT.', 'Imparting value based Professional Education with a sense of Social', 'Responsibility.']\n",
            "[DEBUG:OCR] Raw OCR result preview: [{'input_path': '/tmp/tmpdv21bv6j.png', 'page_index': None, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'input_img': array([[[ 56, ..., 121],\n",
            "        ...,\n",
            "        [ 30, ...,  58]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[123, ..., 179],\n",
            "        ...,\n",
            "        [123, ..., 153]]], shape=(4000, 3000, 3), dtype=uint8), 'model_settings': {'use_doc_orientation_classify': True, 'use_doc_unwarping': True\n",
            "[DEBUG:OCR] Cleaned up temporary file.\n",
            "[OCR RESULTS :] ['Vision Creating Competent IT Professionals with Core Values for the real world\" Mission Providing Students with a Sound Knowledge in IT Fundamentals. Exposing Students to Emerging Frontiers in various domains of IT enabling Continuous Learning. Promoting Excellence in Teaching, Training, Research and Consultancy. Developing Entrepreneurial acumen to venture into Innovative areas of IT. Imparting value based Professional Education with a sense of Social Responsibility.']\n",
            "[OCR RESULTS COMBINED:] Vision Creating Competent IT Professionals with Core Values for the real world\" Mission Providing Students with a Sound Knowledge in IT Fundamentals. Exposing Students to Emerging Frontiers in various domains of IT enabling Continuous Learning. Promoting Excellence in Teaching, Training, Research and Consultancy. Developing Entrepreneurial acumen to venture into Innovative areas of IT. Imparting value based Professional Education with a sense of Social Responsibility.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-10-25T08:21:30+0000 lvl=warn msg=\"Stopping forwarder\" name=http-5000-2102148a-25e4-429a-8aa2-10e318a5b51e acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from IndicTransToolkit.processor import IndicProcessor\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "src_lang, tgt_lang = \"eng_Latn\", \"hin_Deva\"\n",
        "model_name = \"ai4bharat/indictrans2-en-indic-dist-200M\"\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "# Load model with safe fallback for flash attention\n",
        "try:\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "        model_name,\n",
        "        trust_remote_code=True,\n",
        "        torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
        "        attn_implementation=\"flash_attention_2\",\n",
        "    ).to(DEVICE)\n",
        "except Exception as e:\n",
        "    print(\"⚠️ Flash attention not available, using standard attention:\", e)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "        model_name,\n",
        "        trust_remote_code=True,\n",
        "        torch_dtype=torch.float32,\n",
        "    ).to(DEVICE)\n",
        "\n",
        "# Processor\n",
        "ip = IndicProcessor(inference=True)\n",
        "\n",
        "# Example sentences\n",
        "input_sentences = [\n",
        "    \"When I was young, I used to go to the park every day.\",\n",
        "    \"We watched a new movie last week, which was very inspiring.\",\n",
        "    \"If you had met me at that time, we would have gone out to eat.\",\n",
        "    \"My friend has invited me to his birthday party, and I will give him a gift.\",\n",
        "]\n",
        "\n",
        "# Preprocess for IndicTrans\n",
        "preprocessed_batch = ip.preprocess_batch(\n",
        "    input_sentences, src_lang=src_lang, tgt_lang=tgt_lang\n",
        ")\n",
        "\n",
        "# Tokenize\n",
        "inputs = tokenizer(\n",
        "    preprocessed_batch,\n",
        "    return_tensors=\"pt\",\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        ").to(DEVICE)\n",
        "\n",
        "# Generate (with caching disabled)\n",
        "with torch.no_grad():\n",
        "    generated_tokens = model.generate(\n",
        "        **inputs,\n",
        "        use_cache=False,  # <-- critical fix\n",
        "        min_length=1,\n",
        "        max_length=256,\n",
        "        num_beams=5,\n",
        "    )\n",
        "\n",
        "# Decode and postprocess\n",
        "decoded_texts = tokenizer.batch_decode(\n",
        "    generated_tokens,\n",
        "    skip_special_tokens=True,\n",
        "    clean_up_tokenization_spaces=True,\n",
        ")\n",
        "\n",
        "translations = ip.postprocess_batch(decoded_texts, lang=tgt_lang)\n",
        "\n",
        "# Print results\n",
        "for src, tgt in zip(input_sentences, translations):\n",
        "    print(f\"\\n{src_lang}: {src}\")\n",
        "    print(f\"{tgt_lang}: {tgt}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "collapsed": true,
        "id": "EBr7ZB4j8Rw2",
        "outputId": "72074f41-1e11-4059-b8c9-52f19999eeb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "eng_Latn: When I was young, I used to go to the park every day.\n",
            "hin_Deva: जब मैं छोटा था, मैं हर दिन पार्क जाता था।\n",
            "\n",
            "eng_Latn: We watched a new movie last week, which was very inspiring.\n",
            "hin_Deva: हमने पिछले हफ्ते एक नई फिल्म देखी, जो बहुत प्रेरणादायक थी।\n",
            "\n",
            "eng_Latn: If you had met me at that time, we would have gone out to eat.\n",
            "hin_Deva: अगर आप उस समय मुझसे मिलते तो हम बाहर खाना खाने जाते।\n",
            "\n",
            "eng_Latn: My friend has invited me to his birthday party, and I will give him a gift.\n",
            "hin_Deva: मेरे दोस्त ने मुझे अपने जन्मदिन की पार्टी में आमंत्रित किया है, और मैं उसे एक उपहार दूंगा।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# ocr = PaddleOCR(lang=\"en\") # Uses English model by specifying language parameter\n",
        "# ocr = PaddleOCR(ocr_version=\"PP-OCRv4\") # Uses other PP-OCR versions via version parameter\n",
        "# ocr = PaddleOCR(device=\"gpu\") # Enables GPU acceleration for model inference via device parameter\n",
        "# ocr = PaddleOCR(\n",
        "#     text_detection_model_name=\"PP-OCRv5_mobile_det\",\n",
        "#     text_recognition_model_name=\"PP-OCRv5_mobile_rec\",\n",
        "#     use_doc_orientation_classify=False,\n",
        "#     use_doc_unwarping=False,\n",
        "#     use_textline_orientation=False,\n",
        "# )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JMnA5gaOT5HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from paddleocr import PaddleOCR\n",
        "\n",
        "ocr = PaddleOCR(\n",
        "    use_doc_orientation_classify=False,\n",
        "    use_doc_unwarping=False,\n",
        "    use_textline_orientation=False,\n",
        "\n",
        ")\n",
        "result = ocr.predict(\"/content/Screenshot 2025-10-23 230237.jpg\")\n",
        "for res in result:\n",
        "    res.print()"
      ],
      "metadata": {
        "id": "lYNv9Ws5EmMm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556,
          "referenced_widgets": [
            "352e37eb06334a17927adcd6164c58e0",
            "e7182179ff9b4c7f8ddb73ace7754d52",
            "bfd66ddba1d643769589f4a0d32d1c15",
            "9cf9994788b44da3a73e349a0ad70ea3",
            "42a7e4651e5145c0b3c9eda2cc5ae203",
            "fd01dc489262428b9112a84de619c0f7",
            "0871e20bdaca4d6cad797df83c838c99",
            "3c4390631ebb4400a6a723a30a4e8d0b",
            "a2f3a1f7f8524169971b2d72a616f6a0",
            "cf61c5ee9b9f4e20a7e6f9a1724b50c1",
            "8f3c81921e084dea975c5b1468a11088",
            "e568a84d53fc4495a88913e8dc3abf41",
            "507c71f273a942f39828e6ec3d197190",
            "698c40c6048a4286a87ecf7e836a4688",
            "2fb8136896f548d2b167c170cf91a265",
            "b9d359a852b64ad781486593abb55c3e",
            "a425eb1394e84992b846cf150c165018",
            "5496466fc3854dbe8bef0ebaaafae8e8",
            "c410f51d892b41a595125b1bf844ad7c",
            "36ce03fb052046e7b05d4b03a96fc1c3",
            "ed1e63fafdef4d45acd8b28d0638f22e",
            "d243bd9264e249748bce01084122f09d",
            "e68088ebe76948edbf0848bec4ac9f1e",
            "eee9fa44d3fb48409ce017e2a5bdd888",
            "57a1d4191fe34a3c94daa0b70c918584",
            "404d3f2964a84a878ac1eb389909c0ea",
            "8ff8b33402bb43869bcad3aa4066273d",
            "5d692a4ef1104efeb31ff48153892aa3",
            "ca0cf1ea6716465d8bdd6992d7500aeb",
            "2488bb017141429c92c11bf29ef219d2",
            "ff12111d2a1a4cc8ba92f7e863128ba4",
            "201bc473e6fc4aaaa8d77a4fb0e5770c",
            "edcc2db76c6e41e3b64ff3539eaa780b",
            "a9e492f40fa04806a35f6f5c666aca95",
            "59cdac60b2264bc4ba58cc6974730d23",
            "3a5b884465d9457c8e5d8488b5ebc539",
            "e95140de96474ae99aa202de30673674",
            "28e4b90b24254aeeb5f4baae60aabf6e",
            "127a2d578c614cd99e4b6ee62bcd2866",
            "a480e48c73ef46e0b4e1109a0d6fbb87",
            "c33f2d4a654b45d7a7954c1bc39db520",
            "07536c8343534c069d38b0f1685fe2b1",
            "28e3e32da7df4d0eb1cd64efbfa59ba6",
            "feaa8fdbf2e745699745863a42a00037",
            "1f15d6ee58164ec9a0d004e7f9524780",
            "15141b09976e4e5c96831a3cba417d82",
            "e4a34f9df6674e8386bdbbced719c60e",
            "6f4674a9afa94f14acbaa7a4c68121a7",
            "f5cddaf3ee66423389597b85405fbb54",
            "9794344adc634f93b1c55c92000b85ba",
            "f7574b4dda83489d8623130d7a61fb3b",
            "8fe9bb936c8a4ddeafd277dd3b6bda1b",
            "ebeb458fa7c140dcbc8fee6b11858a68",
            "93c0eae46b83449085d06379ad5dc511",
            "bd75caf095874e718f1744e858e9f84a",
            "c5a564e60cdc40cfb99ca62432a7af72",
            "b531c37c35834cbfb08700e7e4dc3d14",
            "202bb1443cad46f9878707df72928d3e",
            "0428c01e41f647dc895eb5a118a9580d",
            "bf646ef907c9461c803add77b653e5f1",
            "a7ba47850e8540acaef4d9f8f2346ac4",
            "3a303c004b284ea4a1a0acf5748c810d",
            "1d5ed43e0692410ba319096e0118c17b",
            "95ec403486f74781ac13999f06fb434e",
            "0e7c9391943246c29130a1265f87a0fb",
            "7c77dbce6ef743e1a5be6e77113a8f9e",
            "2bc3fac4600947a38f6d036931023068",
            "346e8bde618344de856432a33857cf08",
            "7010610ab61b45c58bd7051eb648a414",
            "ac983f32b7834021b543eb07bd09d36e",
            "7c7166d19283460ab40a8f56ea81f3d4",
            "de0061381fde48d89e31099deea963be",
            "cbd58be746f84ea8a92eadb7d232d515",
            "3e7f5aeef0ac4e6dbc526dd02a5732df",
            "738c0caad2304608bc076c4079f62976",
            "8faf3338b91b4b178480d46169a06613",
            "143a2569a4684d438ba9b4cb92a0239a"
          ]
        },
        "outputId": "b3eebfe4-3298-41ad-bcec-6781a492b857",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
            "  warnings.warn(warning_message)\n",
            "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
            "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/root/.paddlex/official_models/PP-OCRv5_server_det`.\u001b[0m\n",
            "\u001b[32mCreating model: ('PP-OCRv5_server_rec', None)\u001b[0m\n",
            "\u001b[32mUsing official model (PP-OCRv5_server_rec), the model files will be automatically downloaded and saved in `/root/.paddlex/official_models/PP-OCRv5_server_rec`.\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "352e37eb06334a17927adcd6164c58e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e568a84d53fc4495a88913e8dc3abf41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "inference.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e68088ebe76948edbf0848bec4ac9f1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "inference.yml: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9e492f40fa04806a35f6f5c666aca95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f15d6ee58164ec9a0d004e7f9524780"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              ".gitattributes: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5a564e60cdc40cfb99ca62432a7af72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "inference.pdiparams:   0%|          | 0.00/84.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bc3fac4600947a38f6d036931023068"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m{'res': {'input_path': '/content/Screenshot 2025-10-23 230237.jpg', 'page_index': None, 'model_settings': {'use_doc_preprocessor': True, 'use_textline_orientation': False}, 'doc_preprocessor_res': {'input_path': None, 'page_index': None, 'model_settings': {'use_doc_orientation_classify': False, 'use_doc_unwarping': False}, 'angle': -1}, 'dt_polys': array([[[103,  63],\n",
            "        ...,\n",
            "        [102, 140]]], shape=(1, 4, 2), dtype=int16), 'text_det_params': {'limit_side_len': 64, 'limit_type': 'min', 'thresh': 0.3, 'max_side_limit': 4000, 'box_thresh': 0.6, 'unclip_ratio': 1.5}, 'text_type': 'general', 'textline_orientation_angles': array([-1]), 'text_rec_score_thresh': 0.0, 'return_word_box': False, 'rec_texts': ['hey hello testing ocr'], 'rec_scores': array([0.98338789]), 'rec_polys': array([[[103,  63],\n",
            "        ...,\n",
            "        [102, 140]]], shape=(1, 4, 2), dtype=int16), 'rec_boxes': array([[102, ..., 147]], shape=(1, 4), dtype=int16)}}\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rec='PP-OCRv5_server_rec'\n",
        "det='PP-OCRv5_server_det'"
      ],
      "metadata": {
        "id": "is3tQjWzTPWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result[0]['rec_texts']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxEDxvcwIfLU",
        "outputId": "5f000549-f14a-4ef1-a7fc-78c10a2ab68f",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hey hello testing ocr']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "geDNyZopIiGT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}